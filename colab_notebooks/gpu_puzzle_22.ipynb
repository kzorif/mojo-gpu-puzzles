{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMPk6XHZuqZvg1YwMhTld1g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwxDPG8tVON9","executionInfo":{"status":"ok","timestamp":1756643832584,"user_tz":-330,"elapsed":32274,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"dbcdc355-d973-4f10-98a4-37f4e6ef08e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n","Collecting max==25.4.0\n","  Downloading https://dl.modular.com/public/nightly/python/max-25.4.0-py3-none-manylinux_2_34_x86_64.whl (285.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.0/285.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (8.2.1)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (2.0.2)\n","Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (4.67.1)\n","Installing collected packages: max\n","Successfully installed max-25.4.0\n"]}],"source":["!pip install max==25.4.0 --index-url https://dl.modular.com/public/nightly/python/simple/"]},{"cell_type":"code","source":["!git clone https://github.com/modular/mojo-gpu-puzzles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aR2UsVbOVTvl","executionInfo":{"status":"ok","timestamp":1756643841372,"user_tz":-330,"elapsed":8792,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"0e63fe3e-4b36-4706-d4cb-67071f837406"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mojo-gpu-puzzles'...\n","remote: Enumerating objects: 6332, done.\u001b[K\n","remote: Counting objects: 100% (481/481), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 6332 (delta 449), reused 416 (delta 416), pack-reused 5851 (from 3)\u001b[K\n","Receiving objects: 100% (6332/6332), 148.64 MiB | 23.96 MiB/s, done.\n","Resolving deltas: 100% (3923/3923), done.\n"]}]},{"cell_type":"code","source":["!curl -fsSL https://astral.sh/uv/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IONO5ku1VVe6","executionInfo":{"status":"ok","timestamp":1756643843002,"user_tz":-330,"elapsed":1625,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"54d63d2d-2887-4730-a895-12a5769517da"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.8.14 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}]},{"cell_type":"code","source":["import max.support.notebook"],"metadata":{"id":"KmTW79N9VWu6","executionInfo":{"status":"ok","timestamp":1756643843009,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def save_code_to_file(text: str, filename: str):\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)"],"metadata":{"id":"slz72jMNVYE4","executionInfo":{"status":"ok","timestamp":1756643843022,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mojo_code = \"\"\"\n","from math import sqrt\n","from gpu import thread_idx, block_idx, block_dim, barrier\n","from gpu.memory import async_copy_wait_all\n","from os.atomic import Atomic\n","from layout import Layout, LayoutTensor\n","from layout.layout_tensor import copy_dram_to_sram_async\n","from layout.tensor_builder import LayoutTensorBuild as tb\n","import compiler\n","from runtime.asyncrt import DeviceContextPtr\n","from tensor import InputTensor, OutputTensor\n","from utils import StaticTuple\n","\n","alias TPB = 16\n","alias dtype = DType.float32\n","\n","\n","# ANCHOR: matmul_idiomatic_tiled\n","# Idiomatic tiled matmul from p14.mojo - adapted for [batch*seq, hidden] @ [hidden, output] -> [batch*seq, output]\n","fn matmul_idiomatic_tiled[\n","    a_layout: Layout,\n","    b_layout: Layout,\n","    out_layout: Layout,\n","    rows: Int,\n","    cols: Int,\n","    inner_dim: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, out_layout],\n","    a: LayoutTensor[mut=False, dtype, a_layout],\n","    b: LayoutTensor[mut=False, dtype, b_layout],\n","):\n","    local_row = thread_idx.x\n","    local_col = thread_idx.y\n","    tiled_row = block_idx.y * TPB + local_row\n","    tiled_col = block_idx.x * TPB + local_col\n","\n","    # Get the tile of the output matrix that this thread block is responsible for\n","    out_tile = output.tile[TPB, TPB](block_idx.x, block_idx.y)\n","    a_shared = tb[dtype]().row_major[TPB, TPB]().shared().alloc().fill(0)\n","    b_shared = tb[dtype]().row_major[TPB, TPB]().shared().alloc().fill(0)\n","\n","    var acc: output.element_type = 0\n","\n","    alias load_a_layout = Layout.row_major(1, TPB)\n","    alias load_b_layout = Layout.row_major(TPB, 1)\n","\n","    for idx in range((inner_dim + TPB - 1) // TPB):\n","        # Get tiles from A and B matrices\n","        a_tile = a.tile[TPB, TPB](block_idx.x, idx)\n","        b_tile = b.tile[TPB, TPB](idx, block_idx.y)\n","\n","        # Asynchronously copy tiles to shared memory\n","        copy_dram_to_sram_async[thread_layout=load_a_layout](a_shared, a_tile)\n","        copy_dram_to_sram_async[thread_layout=load_b_layout](b_shared, b_tile)\n","\n","        # Wait for all async copies to complete\n","        async_copy_wait_all()\n","        barrier()\n","\n","        # Compute partial matrix multiplication for this tile\n","        @parameter\n","        for k in range(TPB):\n","            acc += a_shared[local_row, k] * b_shared[k, local_col]\n","\n","        barrier()\n","\n","    # Write final result with bounds checking (needed for variable matrix sizes)\n","    if tiled_row < rows and tiled_col < cols:\n","        out_tile[local_row, local_col] = acc\n","\n","\n","# ANCHOR_END: matmul_idiomatic_tiled\n","\n","\n","# ANCHOR: layernorm_kernel\n","fn layernorm_kernel[\n","    input_layout: Layout,\n","    ln_params_layout: Layout,\n","    output_layout: Layout,\n","    batch_size: Int,\n","    seq_len: Int,\n","    hidden_dim: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, output_layout],\n","    input: LayoutTensor[mut=False, dtype, input_layout],\n","    ln_weight: LayoutTensor[mut=False, dtype, ln_params_layout],\n","    ln_bias: LayoutTensor[mut=False, dtype, ln_params_layout],\n","):\n","    batch_idx = block_idx.x\n","    seq_idx = block_idx.y\n","    hidden_idx = thread_idx.x\n","\n","    if (\n","        batch_idx >= batch_size\n","        or seq_idx >= seq_len\n","        or hidden_idx >= hidden_dim\n","    ):\n","        return\n","\n","    # Compute statistics for this sequence position (redundant but simple)\n","    var sum_val: Scalar[dtype] = 0\n","    var sq_sum: Scalar[dtype] = 0\n","\n","    # FILL ME IN (roughly 11 lines)\n","    @parameter\n","    for h in range(hidden_dim):\n","      val = input[batch_idx, seq_idx, h]\n","      sum_val += rebind[Scalar[dtype]](val)\n","      sq_sum += rebind[Scalar[dtype]](val * val)\n","\n","    mean_val = sum_val / hidden_dim\n","    var_val = (sq_sum / hidden_dim) - (mean_val * mean_val)\n","    inv_std = 1.0 / sqrt(var_val + 1e-5)\n","\n","    input_val = input[batch_idx, seq_idx, hidden_idx]\n","    normalized = (input_val - mean_val) * inv_std * rebind[Scalar[dtype]](\n","      ln_weight[hidden_idx]\n","    ) + rebind[Scalar[dtype]](ln_bias[hidden_idx])\n","    output[batch_idx, seq_idx, hidden_idx] = normalized\n","\n","# ANCHOR_END: layernorm_kernel\n","\n","\n","# ANCHOR: transpose_kernel\n","fn transpose_kernel[\n","    layout_in: Layout,\n","    layout_out: Layout,\n","    rows: Int,\n","    cols: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, layout_out],\n","    input: LayoutTensor[mut=False, dtype, layout_in],\n","):\n","    shared_tile = tb[dtype]().row_major[TPB, TPB]().shared().alloc()\n","\n","    local_row = thread_idx.y\n","    local_col = thread_idx.x\n","\n","    global_row = block_idx.y * TPB + local_row\n","    global_col = block_idx.x * TPB + local_col\n","\n","    if global_row < rows and global_col < cols:\n","        shared_tile[local_row, local_col] = input[global_row, global_col]\n","    else:\n","        shared_tile[local_row, local_col] = 0.0\n","\n","    barrier()\n","\n","    out_row = block_idx.x * TPB + local_row\n","    out_col = block_idx.y * TPB + local_col\n","\n","    # Store data from shared memory to global memory (coalesced write)\n","    # Note: we transpose the shared memory access pattern\n","    if out_row < cols and out_col < rows:\n","        output[out_row, out_col] = shared_tile[local_col, local_row]\n","\n","\n","# ANCHOR_END: transpose_kernel\n","\n","\n","# ANCHOR: add_bias_kernel\n","fn add_bias_kernel[\n","    input_layout: Layout,\n","    bias_layout: Layout,\n","    output_layout: Layout,\n","    batch_size: Int,\n","    seq_len: Int,\n","    output_dim: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, output_layout],\n","    input: LayoutTensor[mut=False, dtype, input_layout],\n","    bias: LayoutTensor[mut=False, dtype, bias_layout],\n","):\n","    batch_idx = block_idx.x\n","    seq_idx = block_idx.y\n","    out_idx = thread_idx.x\n","\n","    if batch_idx >= batch_size or seq_idx >= seq_len or out_idx >= output_dim:\n","        return\n","\n","    output[batch_idx, seq_idx, out_idx] = input[\n","        batch_idx, seq_idx, out_idx\n","    ] + rebind[Scalar[dtype]](bias[out_idx])\n","\n","\n","# ANCHOR_END: add_bias_kernel\n","\n","\n","# ANCHOR: minimal_fused_forward_kernel\n","fn minimal_fused_kernel[\n","    input_layout: Layout,\n","    ln_params_layout: Layout,\n","    weight_layout: Layout,\n","    bias_layout: Layout,\n","    output_layout: Layout,\n","    batch_size: Int,\n","    seq_len: Int,\n","    hidden_dim: Int,\n","    output_dim: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, output_layout],\n","    input: LayoutTensor[mut=False, dtype, input_layout],\n","    ln_weight: LayoutTensor[mut=False, dtype, ln_params_layout],\n","    ln_bias: LayoutTensor[mut=False, dtype, ln_params_layout],\n","    linear_weight: LayoutTensor[mut=False, dtype, weight_layout],\n","    linear_bias: LayoutTensor[mut=False, dtype, bias_layout],\n","):\n","    # Grid: (batch_size, seq_len) - one thread block per sequence position\n","    # Block: (1,) - single thread per sequence position to avoid redundant computation\n","    batch_idx = block_idx.x\n","    seq_idx = block_idx.y\n","\n","    if batch_idx >= batch_size or seq_idx >= seq_len:\n","        return\n","\n","    # Step 1: Compute LayerNorm statistics once per sequence position\n","    # FILL IN roughly 10 lines\n","    var sum_val: Scalar[dtype] = 0\n","    var sq_sum: Scalar[dtype] = 0\n","\n","    @parameter\n","    for h in range(hidden_dim):\n","      val = input[batch_idx, seq_idx, h]\n","      sum_val += rebind[Scalar[dtype]](val)\n","      sq_sum += rebind[Scalar[dtype]](val * val)\n","\n","    mean_val = sum_val / hidden_dim\n","    var_val = (sq_sum / hidden_dim) - (mean_val * mean_val)\n","    inv_std = 1.0 / sqrt(var_val + 1e-5)\n","\n","    # Step 2: Compute all outputs for this sequence position\n","    # FILL IN roughly 10 lines\n","    @parameter\n","    for out_idx in range(output_dim):\n","      var acc: Scalar[dtype] = 0\n","\n","      @parameter\n","      for h in range(hidden_dim):\n","        input_val = input[batch_idx, seq_idx, h]\n","        normalized = (input_val - mean_val) * inv_std * rebind[Scalar[dtype]](ln_weight[h]) + rebind[Scalar[dtype]](ln_bias[h])\n","        acc += rebind[Scalar[dtype]](normalized * linear_weight[out_idx, h])\n","\n","      output[batch_idx, seq_idx, out_idx] = acc + rebind[Scalar[dtype]](linear_bias[out_idx])\n","\n","\n","# ANCHOR_END: minimal_fused_forward_kernel\n","\n","\n","# ANCHOR: minimal_fused_backward_kernel\n","fn minimal_fused_kernel_backward[\n","    grad_output_layout: Layout,\n","    input_layout: Layout,\n","    ln_params_layout: Layout,\n","    weight_layout: Layout,\n","    grad_input_layout: Layout,\n","    grad_ln_weight_layout: Layout,\n","    grad_ln_bias_layout: Layout,\n","    grad_weight_layout: Layout,\n","    grad_bias_layout: Layout,\n","    batch_size: Int,\n","    seq_len: Int,\n","    hidden_dim: Int,\n","    output_dim: Int,\n","](\n","    grad_input: LayoutTensor[mut=True, dtype, grad_input_layout],\n","    grad_ln_weight: LayoutTensor[mut=True, dtype, grad_ln_weight_layout],\n","    grad_ln_bias: LayoutTensor[mut=True, dtype, grad_ln_bias_layout],\n","    grad_weight: LayoutTensor[mut=True, dtype, grad_weight_layout],\n","    grad_bias: LayoutTensor[mut=True, dtype, grad_bias_layout],\n","    grad_output: LayoutTensor[mut=False, dtype, grad_output_layout],\n","    input: LayoutTensor[mut=False, dtype, input_layout],\n","    ln_weight: LayoutTensor[mut=False, dtype, ln_params_layout],\n","    ln_bias: LayoutTensor[mut=False, dtype, ln_params_layout],\n","    linear_weight: LayoutTensor[mut=False, dtype, weight_layout],\n","):\n","    # Grid: (batch_size, seq_len) - one thread per sequence position\n","    # Block: (1,) - single thread per sequence position\n","    batch_idx = block_idx.x\n","    seq_idx = block_idx.y\n","\n","    if batch_idx >= batch_size or seq_idx >= seq_len:\n","        return\n","\n","    # Step 1: Recompute forward pass statistics (needed for gradients)\n","    var sum_val: Scalar[dtype] = 0\n","    var sq_sum: Scalar[dtype] = 0\n","\n","    # FILL IN roughly 8 lines\n","    @parameter\n","    for h in range(hidden_dim):\n","      val = input[batch_idx, seq_idx, h]\n","      sum_val += rebind[Scalar[dtype]](val)\n","      sq_sum += rebind[Scalar[dtype]](val * val)\n","\n","    mean_val = sum_val / hidden_dim\n","    var_val = (sq_sum / hidden_dim) - (mean_val * mean_val)\n","    inv_std = 1.0 / sqrt(var_val + 1e-5)\n","\n","    # Step 2: Atomically accumulate gradients w.r.t. linear bias\n","    # FILL IN roughly 4 lines\n","    @parameter\n","    for out_idx in range(output_dim):\n","      grad_bias_ptr = grad_bias.ptr.offset(out_idx)\n","      _ = Atomic[dtype].fetch_add(\n","        grad_bias_ptr,\n","        rebind[Scalar[dtype]](grad_output[batch_idx, seq_idx, out_idx]),\n","      )\n","\n","    # Step 3: Atomically accumulate gradients w.r.t. linear weight\n","    # Make sure to use the correct atomic operation to avoid race conditions\n","    # FILL IN roughly 10 lines\n","\n","    @parameter\n","    for out_idx in range(output_dim):\n","      @parameter\n","      for h in range(hidden_dim):\n","        var input_val = input[batch_idx, seq_idx, h]\n","        var normalized = (input_val - mean_val) * inv_std\n","        var ln_output_val = normalized * rebind[Scalar[dtype]](ln_weight[h]) + rebind[Scalar[dtype]](ln_bias[h])\n","\n","        var grad_w = (grad_output[batch_idx, seq_idx, out_idx] * ln_output_val)\n","        var grad_weight_ptr = grad_weight.ptr.offset(out_idx * hidden_dim + h)\n","\n","        _ = Atomic[dtype].fetch_add(grad_weight_ptr, rebind[Scalar[dtype]](grad_w))\n","\n","    # Step 4: Atomically accumulate gradients w.r.t. LayerNorm parameters\n","    # FILL IN roughly 10 lines\n","    @parameter\n","    for h in range(hidden_dim):\n","      input_val = input[batch_idx, seq_idx, h]\n","      normalized = (input_val - mean_val) * inv_std\n","\n","      var grad_ln_out: Scalar[dtype] = 0\n","\n","      @parameter\n","      for out_idx in range(output_dim):\n","        grad_ln_out = grad_ln_out + rebind[Scalar[dtype]](grad_output[batch_idx, seq_idx, out_idx] * linear_weight[out_idx, h])\n","\n","      grad_ln_weight_ptr = grad_ln_weight.ptr.offset(h)\n","      grad_ln_bias_ptr = grad_ln_bias.ptr.offset(h)\n","\n","      _ = Atomic[dtype].fetch_add(grad_ln_weight_ptr, rebind[Scalar[dtype]](grad_ln_out * normalized))\n","      _ = Atomic[dtype].fetch_add(grad_ln_bias_ptr, rebind[Scalar[dtype]](grad_ln_out))\n","\n","    # Step 5: Compute gradients w.r.t. input (LayerNorm backward)\n","    # Compute sum terms needed for LayerNorm backward\n","    # Make sure to use the correct atomic operation to avoid race conditions\n","    # FILL IN roughly 12 lines\n","    var sum_grad_normalized: Scalar[dtype] = 0\n","    var sum_grad_normalized_times_normalized: Scalar[dtype] = 0\n","\n","    @parameter\n","    for h in range(hidden_dim):\n","      h_input_val = input[batch_idx, seq_idx, h]\n","      h_normalized = (h_input_val - mean_val) * inv_std\n","\n","      var h_grad_ln_out: Scalar[dtype] = 0\n","\n","      @parameter\n","      for out_idx in range(output_dim):\n","        h_grad_ln_out = h_grad_ln_out + rebind[Scalar[dtype]](grad_output[batch_idx, seq_idx, out_idx] * linear_weight[out_idx, h])\n","\n","      h_grad_norm = h_grad_ln_out * rebind[Scalar[dtype]](ln_weight[h])\n","      sum_grad_normalized = sum_grad_normalized + rebind[Scalar[dtype]](h_grad_norm)\n","      sum_grad_normalized_times_normalized = (sum_grad_normalized_times_normalized + rebind[Scalar[dtype]](h_grad_norm * h_normalized))\n","\n","\n","    # Compute actual input gradients (no race conditions here - each thread writes to different positions\n","    # FILL IN roughly 10 lines\n","    @parameter\n","    for h in range(hidden_dim):\n","      h_input_val = input[batch_idx, seq_idx, h]\n","      h_normalized = (h_input_val - mean_val) * inv_std\n","\n","      var h_grad_ln_out: Scalar[dtype] = 0\n","\n","      @parameter\n","      for out_idx in range(output_dim):\n","        h_grad_ln_out = h_grad_ln_out + rebind[Scalar[dtype]](grad_output[batch_idx, seq_idx, out_idx] * linear_weight[out_idx, h])\n","      h_grad_norm = h_grad_ln_out * rebind[Scalar[dtype]](ln_weight[h])\n","      grad_input[batch_idx, seq_idx, h] = inv_std * (h_grad_norm - (sum_grad_normalized / hidden_dim) - (h_normalized * sum_grad_normalized_times_normalized / hidden_dim))\n","\n","# ANCHOR_END: minimal_fused_backward_kernel\n","\n","\n","@compiler.register(\"layernorm_linear\")\n","struct LayerNormLinearCustomOp:\n","    @staticmethod\n","    fn execute[\n","        target: StaticString,\n","        algorithm: StaticString,\n","        batch_size: Int,\n","        seq_len: Int,\n","        hidden_dim: Int,\n","        output_dim: Int,\n","    ](\n","        output: OutputTensor[dtype = DType.float32, rank=3],\n","        input: InputTensor[dtype = DType.float32, rank=3],\n","        ln_weight: InputTensor[dtype = DType.float32, rank=1],\n","        ln_bias: InputTensor[dtype = DType.float32, rank=1],\n","        linear_weight: InputTensor[dtype = DType.float32, rank=2],\n","        linear_bias: InputTensor[dtype = DType.float32, rank=1],\n","        ctx: DeviceContextPtr,\n","    ) raises:\n","        output_tensor = output.to_layout_tensor()\n","        input_tensor = input.to_layout_tensor()\n","        ln_weight_tensor = ln_weight.to_layout_tensor()\n","        ln_bias_tensor = ln_bias.to_layout_tensor()\n","        linear_weight_tensor = linear_weight.to_layout_tensor()\n","        linear_bias_tensor = linear_bias.to_layout_tensor()\n","\n","        alias input_layout = input_tensor.layout\n","        alias ln_params_layout = ln_weight_tensor.layout\n","        alias weight_layout = linear_weight_tensor.layout\n","        alias bias_layout = linear_bias_tensor.layout\n","        alias output_layout = output_tensor.layout\n","\n","        @parameter\n","        if target == \"gpu\":\n","            gpu_ctx = ctx.get_device_context()\n","\n","            # ANCHOR: layernorm_linear_custom_op\n","            @parameter\n","            if algorithm == \"fused\":\n","                # fused case - one thread per sequence position\n","                gpu_ctx.enqueue_function[\n","                    minimal_fused_kernel[\n","                        input_layout,\n","                        ln_params_layout,\n","                        weight_layout,\n","                        bias_layout,\n","                        output_layout,\n","                        batch_size,\n","                        seq_len,\n","                        hidden_dim,\n","                        output_dim,\n","                    ]\n","                ](\n","                    output_tensor,\n","                    input_tensor,\n","                    ln_weight_tensor,\n","                    ln_bias_tensor,\n","                    linear_weight_tensor,\n","                    linear_bias_tensor,\n","                    grid_dim=(batch_size, seq_len),\n","                    block_dim=(1,),\n","                )\n","            elif algorithm == \"unfused\":\n","                # unfused case\n","                # Create intermediate normalized tensor\n","                normalized_buffer = gpu_ctx.enqueue_create_buffer[dtype](\n","                    batch_size * seq_len * hidden_dim\n","                )\n","                normalized_tensor = LayoutTensor[mut=True, dtype, input_layout](\n","                    normalized_buffer.unsafe_ptr()\n","                )\n","\n","                # Step 1: LayerNorm kernel\n","                gpu_ctx.enqueue_function[\n","                    layernorm_kernel[\n","                        input_layout,\n","                        ln_params_layout,\n","                        input_layout,\n","                        batch_size,\n","                        seq_len,\n","                        hidden_dim,\n","                    ]\n","                ](\n","                    normalized_tensor,\n","                    input_tensor,\n","                    ln_weight_tensor,\n","                    ln_bias_tensor,\n","                    grid_dim=(batch_size, seq_len),\n","                    block_dim=(min(hidden_dim, TPB),),\n","                )\n","\n","                # Step 2: Matmul on normalized data\n","                total_rows = batch_size * seq_len\n","                blocks_x = (total_rows + TPB - 1) // TPB\n","                blocks_y = (output_dim + TPB - 1) // TPB\n","\n","                # Create intermediate result without bias\n","                matmul_buffer = gpu_ctx.enqueue_create_buffer[dtype](\n","                    batch_size * seq_len * output_dim\n","                )\n","                matmul_tensor = LayoutTensor[mut=True, dtype, output_layout](\n","                    matmul_buffer.unsafe_ptr()\n","                )\n","\n","                # Create transposed weight matrix: [output_dim, hidden_dim] -> [hidden_dim, output_dim]\n","                transposed_weight_buffer = gpu_ctx.enqueue_create_buffer[dtype](\n","                    hidden_dim * output_dim\n","                )\n","                transposed_weight_tensor = LayoutTensor[\n","                    mut=True, dtype, Layout.row_major(hidden_dim, output_dim)\n","                ](transposed_weight_buffer.unsafe_ptr())\n","\n","                # Transpose the weight matrix\n","                transpose_blocks_x = (hidden_dim + TPB - 1) // TPB\n","                transpose_blocks_y = (output_dim + TPB - 1) // TPB\n","                gpu_ctx.enqueue_function[\n","                    transpose_kernel[\n","                        weight_layout,\n","                        transposed_weight_tensor.layout,\n","                        output_dim,\n","                        hidden_dim,\n","                    ]\n","                ](\n","                    transposed_weight_tensor,\n","                    linear_weight_tensor,\n","                    grid_dim=(transpose_blocks_x, transpose_blocks_y),\n","                    block_dim=(TPB, TPB),\n","                )\n","\n","                # Reshape tensors for matmul: [batch*seq, hidden] @ [hidden, output] -> [batch*seq, output]\n","                flat_normalized = normalized_tensor.reshape[\n","                    Layout.row_major(batch_size * seq_len, hidden_dim)\n","                ]()\n","                flat_matmul = matmul_tensor.reshape[\n","                    Layout.row_major(batch_size * seq_len, output_dim)\n","                ]()\n","\n","                gpu_ctx.enqueue_function[\n","                    matmul_idiomatic_tiled[\n","                        flat_normalized.layout,\n","                        transposed_weight_tensor.layout,\n","                        flat_matmul.layout,\n","                        batch_size * seq_len,\n","                        output_dim,\n","                        hidden_dim,\n","                    ]\n","                ](\n","                    flat_matmul,\n","                    flat_normalized,\n","                    transposed_weight_tensor,\n","                    grid_dim=(blocks_x, blocks_y),\n","                    block_dim=(TPB, TPB),\n","                )\n","\n","                # Step 3: Add bias - reshape matmul result back to 3D for bias addition\n","                reshaped_matmul = matmul_tensor.reshape[\n","                    Layout.row_major(batch_size, seq_len, output_dim)\n","                ]()\n","\n","                gpu_ctx.enqueue_function[\n","                    add_bias_kernel[\n","                        reshaped_matmul.layout,\n","                        bias_layout,\n","                        output_layout,\n","                        batch_size,\n","                        seq_len,\n","                        output_dim,\n","                    ]\n","                ](\n","                    output_tensor,\n","                    reshaped_matmul,\n","                    linear_bias_tensor,\n","                    grid_dim=(batch_size, seq_len),\n","                    block_dim=(min(output_dim, TPB),),\n","                )\n","            # ANCHOR_END: layernorm_linear_custom_op\n","\n","        elif target == \"cpu\":\n","            # CPU implementation - always fused (no separate kernels for CPU)\n","            # Note: CPU doesn't have separate fused vs unfused - both use the same implementation\n","            for batch in range(batch_size):\n","                for seq in range(seq_len):\n","                    # LayerNorm\n","                    var sum_val: Scalar[dtype] = 0\n","                    for h in range(hidden_dim):\n","                        sum_val += rebind[Scalar[dtype]](\n","                            input_tensor[batch, seq, h]\n","                        )\n","                    mean_val = sum_val / hidden_dim\n","\n","                    var var_sum: Scalar[dtype] = 0\n","                    for h in range(hidden_dim):\n","                        diff = input_tensor[batch, seq, h] - mean_val\n","                        var_sum += rebind[Scalar[dtype]](diff * diff)\n","                    var_val = var_sum / hidden_dim\n","                    inv_std = 1.0 / sqrt(var_val + 1e-5)\n","\n","                    # Apply LayerNorm and Linear in one step (truly fused)\n","                    for out_idx in range(output_dim):\n","                        var acc: Scalar[dtype] = 0\n","                        for h in range(hidden_dim):\n","                            input_val = input_tensor[batch, seq, h]\n","                            normalized = (\n","                                input_val - mean_val\n","                            ) * inv_std * ln_weight_tensor[h] + ln_bias_tensor[\n","                                h\n","                            ]\n","                            acc += rebind[Scalar[dtype]](\n","                                normalized * linear_weight_tensor[out_idx, h]\n","                            )\n","                        output_tensor[batch, seq, out_idx] = (\n","                            acc + linear_bias_tensor[out_idx]\n","                        )\n","\n","        else:\n","            raise Error(\"Unsupported target: \" + target)\n","\n","\n","# ANCHOR: layernorm_linear_backward_custom_op\n","@compiler.register(\"layernorm_linear_backward\")\n","struct LayerNormLinearBackwardCustomOp:\n","    @staticmethod\n","    fn execute[\n","        target: StaticString,\n","        batch_size: Int,\n","        seq_len: Int,\n","        hidden_dim: Int,\n","        output_dim: Int,\n","    ](\n","        grad_input: OutputTensor[dtype = DType.float32, rank=3],\n","        grad_ln_weight: OutputTensor[dtype = DType.float32, rank=1],\n","        grad_ln_bias: OutputTensor[dtype = DType.float32, rank=1],\n","        grad_weight: OutputTensor[dtype = DType.float32, rank=2],\n","        grad_bias: OutputTensor[dtype = DType.float32, rank=1],\n","        grad_output: InputTensor[dtype = DType.float32, rank=3],\n","        input: InputTensor[dtype = DType.float32, rank=3],\n","        ln_weight: InputTensor[dtype = DType.float32, rank=1],\n","        ln_bias: InputTensor[dtype = DType.float32, rank=1],\n","        linear_weight: InputTensor[dtype = DType.float32, rank=2],\n","        ctx: DeviceContextPtr,\n","    ) raises:\n","        grad_input_tensor = grad_input.to_layout_tensor()\n","        grad_ln_weight_tensor = grad_ln_weight.to_layout_tensor()\n","        grad_ln_bias_tensor = grad_ln_bias.to_layout_tensor()\n","        grad_weight_tensor = grad_weight.to_layout_tensor()\n","        grad_bias_tensor = grad_bias.to_layout_tensor()\n","\n","        grad_output_tensor = grad_output.to_layout_tensor()\n","        input_tensor = input.to_layout_tensor()\n","        ln_weight_tensor = ln_weight.to_layout_tensor()\n","        ln_bias_tensor = ln_bias.to_layout_tensor()\n","        linear_weight_tensor = linear_weight.to_layout_tensor()\n","\n","        alias grad_output_layout = grad_output_tensor.layout\n","        alias input_layout = input_tensor.layout\n","        alias ln_params_layout = ln_weight_tensor.layout\n","        alias weight_layout = linear_weight_tensor.layout\n","        alias grad_input_layout = grad_input_tensor.layout\n","        alias grad_ln_weight_layout = grad_ln_weight_tensor.layout\n","        alias grad_ln_bias_layout = grad_ln_bias_tensor.layout\n","        alias grad_weight_layout = grad_weight_tensor.layout\n","        alias grad_bias_layout = grad_bias_tensor.layout\n","\n","        @parameter\n","        if target == \"gpu\":\n","            gpu_ctx = ctx.get_device_context()\n","            # Zeros added here\n","\n","            # Launch backward kernel\n","            gpu_ctx.enqueue_function[\n","                minimal_fused_kernel_backward[\n","                    grad_output_layout,\n","                    input_layout,\n","                    ln_params_layout,\n","                    weight_layout,\n","                    grad_input_layout,\n","                    grad_ln_weight_layout,\n","                    grad_ln_bias_layout,\n","                    grad_weight_layout,\n","                    grad_bias_layout,\n","                    batch_size,\n","                    seq_len,\n","                    hidden_dim,\n","                    output_dim,\n","                ]\n","            ](\n","                grad_input_tensor,\n","                grad_ln_weight_tensor,\n","                grad_ln_bias_tensor,\n","                grad_weight_tensor,\n","                grad_bias_tensor,\n","                grad_output_tensor,\n","                input_tensor,\n","                ln_weight_tensor,\n","                ln_bias_tensor,\n","                linear_weight_tensor,\n","                grid_dim=(batch_size, seq_len),\n","                block_dim=(1,),\n","            )\n","\n","            # Note: Parameter gradients (ln_weight, ln_bias, linear_weight, bias) are not computed in this kernel\n","            # This is a simplified version that only computes input gradients to avoid race conditions\n","\n","        elif target == \"cpu\":\n","            # CPU implementation - same logic as GPU but in CPU loops\n","            # Initialize gradients to zero\n","            for batch in range(batch_size):\n","                for seq in range(seq_len):\n","                    for h in range(hidden_dim):\n","                        grad_input_tensor[batch, seq, h] = 0.0\n","\n","            for h in range(hidden_dim):\n","                grad_ln_weight_tensor[h] = 0.0\n","                grad_ln_bias_tensor[h] = 0.0\n","\n","            for out_idx in range(output_dim):\n","                grad_bias_tensor[out_idx] = 0.0\n","                for h in range(hidden_dim):\n","                    grad_weight_tensor[out_idx, h] = 0.0\n","\n","            # Compute gradients - same algorithm as GPU kernel\n","            for batch in range(batch_size):\n","                for seq in range(seq_len):\n","                    # Recompute forward pass statistics\n","                    var sum_val: Scalar[dtype] = 0\n","                    for h in range(hidden_dim):\n","                        sum_val += rebind[Scalar[dtype]](\n","                            input_tensor[batch, seq, h]\n","                        )\n","                    mean_val = sum_val / hidden_dim\n","\n","                    var var_sum: Scalar[dtype] = 0\n","                    for h in range(hidden_dim):\n","                        diff = input_tensor[batch, seq, h] - mean_val\n","                        var_sum += rebind[Scalar[dtype]](diff * diff)\n","                    var_val = var_sum / hidden_dim\n","                    inv_std = 1.0 / sqrt(var_val + 1e-5)\n","\n","                    # Gradient w.r.t. linear bias\n","                    for out_idx in range(output_dim):\n","                        grad_bias_tensor[out_idx] = (\n","                            grad_bias_tensor[out_idx]\n","                            + grad_output_tensor[batch, seq, out_idx]\n","                        )\n","\n","                    # Gradient w.r.t. linear weight\n","                    for out_idx in range(output_dim):\n","                        for h in range(hidden_dim):\n","                            input_val = rebind[Scalar[dtype]](\n","                                input_tensor[batch, seq, h]\n","                            )\n","                            normalized = (input_val - mean_val) * inv_std\n","                            ln_output_val = (\n","                                normalized * ln_weight_tensor[h]\n","                                + ln_bias_tensor[h]\n","                            )\n","                            grad_weight_tensor[out_idx, h] = (\n","                                grad_weight_tensor[out_idx, h]\n","                                + grad_output_tensor[batch, seq, out_idx]\n","                                * ln_output_val\n","                            )\n","\n","                    # Gradient w.r.t. LayerNorm parameters\n","                    for h in range(hidden_dim):\n","                        input_val = rebind[Scalar[dtype]](\n","                            input_tensor[batch, seq, h]\n","                        )\n","                        normalized = (input_val - mean_val) * inv_std\n","\n","                        var grad_ln_out: Scalar[dtype] = 0\n","                        for out_idx in range(output_dim):\n","                            grad_ln_out = grad_ln_out + rebind[Scalar[dtype]](\n","                                grad_output_tensor[batch, seq, out_idx]\n","                                * linear_weight_tensor[out_idx, h]\n","                            )\n","\n","                        grad_ln_weight_tensor[h] = grad_ln_weight_tensor[\n","                            h\n","                        ] + rebind[Scalar[dtype]](grad_ln_out * normalized)\n","                        grad_ln_bias_tensor[h] = grad_ln_bias_tensor[\n","                            h\n","                        ] + rebind[Scalar[dtype]](grad_ln_out)\n","\n","                    # Gradient w.r.t. input (LayerNorm backward)\n","                    var sum_grad_normalized: Scalar[dtype] = 0\n","                    var sum_grad_normalized_times_normalized: Scalar[dtype] = 0\n","\n","                    for h in range(hidden_dim):\n","                        input_val = rebind[Scalar[dtype]](\n","                            input_tensor[batch, seq, h]\n","                        )\n","                        normalized = (input_val - mean_val) * inv_std\n","\n","                        var grad_ln_out: Scalar[dtype] = 0\n","                        for out_idx in range(output_dim):\n","                            grad_ln_out = grad_ln_out + rebind[Scalar[dtype]](\n","                                grad_output_tensor[batch, seq, out_idx]\n","                                * linear_weight_tensor[out_idx, h]\n","                            )\n","\n","                        grad_norm = grad_ln_out * ln_weight_tensor[h]\n","                        sum_grad_normalized = sum_grad_normalized + rebind[\n","                            Scalar[dtype]\n","                        ](grad_norm)\n","                        sum_grad_normalized_times_normalized = (\n","                            sum_grad_normalized_times_normalized\n","                            + rebind[Scalar[dtype]](grad_norm * normalized)\n","                        )\n","\n","                    for h in range(hidden_dim):\n","                        input_val = rebind[Scalar[dtype]](\n","                            input_tensor[batch, seq, h]\n","                        )\n","                        normalized = (input_val - mean_val) * inv_std\n","\n","                        var grad_ln_out: Scalar[dtype] = 0\n","                        for out_idx in range(output_dim):\n","                            grad_ln_out = grad_ln_out + rebind[Scalar[dtype]](\n","                                grad_output_tensor[batch, seq, out_idx]\n","                                * linear_weight_tensor[out_idx, h]\n","                            )\n","\n","                        grad_norm = grad_ln_out * ln_weight_tensor[h]\n","                        grad_input_tensor[batch, seq, h] = inv_std * (\n","                            grad_norm\n","                            - (sum_grad_normalized / hidden_dim)\n","                            - (\n","                                normalized\n","                                * sum_grad_normalized_times_normalized\n","                                / hidden_dim\n","                            )\n","                        )\n","\n","        else:\n","            raise Error(\"Unsupported target: \" + target)\n","\n","\n","# ANCHOR_END: layernorm_linear_backward_custom_op\n","\"\"\""],"metadata":{"id":"2hueSZiBVaW3","executionInfo":{"status":"ok","timestamp":1756645152967,"user_tz":-330,"elapsed":132,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["save_code_to_file(mojo_code, \"/content/mojo-gpu-puzzles/problems/p22/op/layernorm_linear.mojo\")"],"metadata":{"id":"cJ7FxVvRVaYz","executionInfo":{"status":"ok","timestamp":1756645153038,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["!cd /content/mojo-gpu-puzzles && uv run poe p22 --backward"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xa7vKpvfVaaw","executionInfo":{"status":"ok","timestamp":1756645202504,"user_tz":-330,"elapsed":49176,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"531c5e30-90fd-492d-cf59-8d926f08ed74"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[37mPoe =>\u001b[0m \u001b[94mpython problems/p22/p22.py --backward\u001b[0m\n","Testing with dimensions: [4, 4, 8] -> [4, 4, 16]\n","✅ Loaded Mojo operations library\n","============================================================\n","           Comprehensive Backward Pass Test\n","           Testing Custom LayerNorm + Linear Gradients\n","============================================================\n","Testing with dimensions: [4, 4, 8] -> [4, 4, 16]\n","\n","Testing CPU Backward Pass:\n","\n","Testing CPU Backward Implementation - Backward Pass\n","---------------------------------------------------------\n","   Computing PyTorch autograd reference...\n","   Computing Mojo backward implementation (CPU)...\n","✅ CPU Backward Implementation backward completed\n","   Forward max difference: 1.49e-08\n","   grad_input: 5.96e-08 ✅\n","   grad_ln_weight: 5.96e-08 ✅\n","   grad_ln_bias: 4.77e-07 ✅\n","   grad_linear_weight: 1.43e-06 ✅\n","   grad_linear_bias: 0.00e+00 ✅\n","\n","   Forward pass: ✅ CORRECT\n","   Gradients:    ✅ CORRECT\n","   Overall:      ✅ CORRECT\n","\n","Testing GPU Backward Pass:\n","\n","Testing GPU Backward Implementation - Backward Pass\n","---------------------------------------------------------\n","   Computing PyTorch autograd reference...\n","   Computing Mojo backward implementation (GPU)...\n","skipping cudagraphs due to mutated inputs (1 instances). Found from : \n","   File \"/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py\", line 70, in inner\n","    return fn(*args, **kwargs)\n","  File \"/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/max/torch/torch.py\", line 203, in __call__\n","    return self._custom_op_def(*args, **kwargs)\n","  File \"/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/torch/_library/custom_ops.py\", line 671, in __call__\n","    return self._opoverload(*args, **kwargs)\n","\n","skipping cudagraphs due to mutated inputs (5 instances). Found from : \n","   File \"/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py\", line 70, in inner\n","    return fn(*args, **kwargs)\n","  File \"/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/max/torch/torch.py\", line 203, in __call__\n","    return self._custom_op_def(*args, **kwargs)\n","  File \"/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/torch/_library/custom_ops.py\", line 671, in __call__\n","    return self._opoverload(*args, **kwargs)\n","\n","✅ GPU Backward Implementation backward completed\n","   Forward max difference: 1.86e-08\n","   grad_input: 4.47e-08 ✅\n","   grad_ln_weight: 6.35e-02 ❌\n","   grad_ln_bias: 6.62e-02 ❌\n","   grad_linear_weight: 9.54e-07 ✅\n","   grad_linear_bias: 0.00e+00 ✅\n","\n","   Forward pass: ✅ CORRECT\n","   Gradients:    ❌ INCORRECT\n","   Overall:      ❌ INCORRECT\n","\n","Backward Pass Test Summary:\n","   - CPU Backward:  ✅ CORRECT\n","   - GPU Backward:  ❌ INCORRECT\n","\n","   Overall Result: ❌ SOME FAILED\n","\n","❌ Some backward pass tests failed!\n","   Check the error messages above for details.\n"]}]},{"cell_type":"code","source":["!uv run mojo --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbSn1DJtVacu","executionInfo":{"status":"ok","timestamp":1756645796150,"user_tz":-330,"elapsed":1008,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"b3122787-afdc-4f76-be21-1b523e5d858f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Mojo 25.4.0 (fbeca2fa)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PEQ1MnrjP1It"},"execution_count":null,"outputs":[]}]}