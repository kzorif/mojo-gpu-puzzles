{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nf405nQCeaWqfhum1waWsirQhJSyypq2","timestamp":1756950184135}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FxmA4enIqqx","executionInfo":{"status":"ok","timestamp":1756666368264,"user_tz":-330,"elapsed":31125,"user":{"displayName":"firoz","userId":"03277806218454595224"}},"outputId":"61a2c4f0-dffe-4a2b-dd3f-644af2f12716"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n","Collecting max==25.4.0\n","  Downloading https://dl.modular.com/public/nightly/python/max-25.4.0-py3-none-manylinux_2_34_x86_64.whl (285.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.0/285.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (8.2.1)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (2.0.2)\n","Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (4.67.1)\n","Installing collected packages: max\n","Successfully installed max-25.4.0\n"]}],"source":["!pip install max==25.4.0 --index-url https://dl.modular.com/public/nightly/python/simple/"]},{"cell_type":"code","source":["!git clone https://github.com/modular/mojo-gpu-puzzles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MAZhBZ_1I0B_","executionInfo":{"status":"ok","timestamp":1756666380289,"user_tz":-330,"elapsed":12027,"user":{"displayName":"firoz","userId":"03277806218454595224"}},"outputId":"5fad83cb-5d08-42a9-9c6a-27c8124da962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mojo-gpu-puzzles'...\n","remote: Enumerating objects: 6332, done.\u001b[K\n","remote: Counting objects: 100% (481/481), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 6332 (delta 449), reused 416 (delta 416), pack-reused 5851 (from 3)\u001b[K\n","Receiving objects: 100% (6332/6332), 148.65 MiB | 16.32 MiB/s, done.\n","Resolving deltas: 100% (3923/3923), done.\n"]}]},{"cell_type":"code","source":["!curl -fsSL https://astral.sh/uv/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCqkts8WI1yT","executionInfo":{"status":"ok","timestamp":1756666382994,"user_tz":-330,"elapsed":2697,"user":{"displayName":"firoz","userId":"03277806218454595224"}},"outputId":"370db0a0-d776-433d-a766-05933fc02ac6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.8.14 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}]},{"cell_type":"code","source":["import max.support.notebook"],"metadata":{"id":"gxhVD3bFI4KQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_code_to_file(text: str, filename: str):\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)"],"metadata":{"id":"wtQMqtxjI5pU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mojo_code = \"\"\"\n","from gpu import thread_idx, block_dim, block_idx, barrier\n","from gpu.host import DeviceContext\n","from gpu.host.compile import get_gpu_target\n","from layout import Layout, LayoutTensor\n","from layout.tensor_builder import LayoutTensorBuild as tb\n","from utils import IndexList\n","from math import log2\n","from algorithm.functional import elementwise, vectorize\n","from sys.info import simdwidthof, alignof\n","from sys.arg import argv\n","from testing import assert_equal\n","from benchmark import Bench, BenchConfig, Bencher, BenchId, keep\n","\n","# ANCHOR: elementwise_add\n","alias SIZE = 1024\n","alias rank = 1\n","alias layout = Layout.row_major(SIZE)\n","alias dtype = DType.float32\n","alias SIMD_WIDTH = simdwidthof[Float32, target = get_gpu_target()]()\n","\n","\n","fn elementwise_add[\n","    layout: Layout, dtype: DType, simd_width: Int, rank: Int, size: Int\n","](\n","    output: LayoutTensor[mut=True, dtype, layout, MutableAnyOrigin],\n","    a: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    b: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    ctx: DeviceContext,\n",") raises:\n","    @parameter\n","    @always_inline\n","    fn add[\n","        simd_width: Int, rank: Int, alignment: Int = alignof[dtype]()\n","    ](indices: IndexList[rank]) capturing -> None:\n","        idx = indices[0]\n","        print(\"idx:\", idx)\n","        # FILL IN (2 to 4 lines)\n","        a_simd = a.load[simd_width](idx, 0)\n","        b_simd = b.load[simd_width](idx, 0)\n","        ret = a_simd + b_simd\n","        output.store[simd_width](idx, 0, ret)\n","    elementwise[add, SIMD_WIDTH, target=\"gpu\"](a.size(), ctx)\n","\n","\n","# ANCHOR_END: elementwise_add\n","\n","\n","# ANCHOR: tiled_elementwise_add\n","alias TILE_SIZE = 32\n","\n","\n","fn tiled_elementwise_add[\n","    layout: Layout,\n","    dtype: DType,\n","    simd_width: Int,\n","    rank: Int,\n","    size: Int,\n","    tile_size: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, layout, MutableAnyOrigin],\n","    a: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    b: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    ctx: DeviceContext,\n",") raises:\n","    @parameter\n","    @always_inline\n","    fn process_tiles[\n","        simd_width: Int, rank: Int, alignment: Int = alignof[dtype]()\n","    ](indices: IndexList[rank]) capturing -> None:\n","        tile_id = indices[0]\n","        print(\"tile_id:\", tile_id)\n","        output_tile = output.tile[tile_size](tile_id)\n","        a_tile = a.tile[tile_size](tile_id)\n","        b_tile = b.tile[tile_size](tile_id)\n","\n","        # FILL IN (6 lines at most)\n","        @parameter\n","        for i in range(tile_size):\n","          a_vec = a_tile.load[simd_width](i, 0)\n","          b_vec = b_tile.load[simd_width](i, 0)\n","          ret = a_vec + b_vec\n","          output_tile.store[simd_width](i, 0, ret)\n","    num_tiles = (size + tile_size - 1) // tile_size\n","    elementwise[process_tiles, 1, target=\"gpu\"](num_tiles, ctx)\n","\n","\n","# ANCHOR_END: tiled_elementwise_add\n","\n","\n","# ANCHOR: manual_vectorized_tiled_elementwise_add\n","fn manual_vectorized_tiled_elementwise_add[\n","    layout: Layout,\n","    dtype: DType,\n","    simd_width: Int,\n","    num_threads_per_tile: Int,\n","    rank: Int,\n","    size: Int,\n","    tile_size: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, layout, MutableAnyOrigin],\n","    a: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    b: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    ctx: DeviceContext,\n",") raises:\n","    # Each tile contains tile_size groups of simd_width elements\n","    alias chunk_size = tile_size * simd_width\n","\n","    @parameter\n","    @always_inline\n","    fn process_manual_vectorized_tiles[\n","        num_threads_per_tile: Int, rank: Int, alignment: Int = alignof[dtype]()\n","    ](indices: IndexList[rank]) capturing -> None:\n","        tile_id = indices[0]\n","        print(\"tile_id:\", tile_id)\n","        out_tile = output.tile[chunk_size](tile_id)\n","        a_tile = a.tile[chunk_size](tile_id)\n","        b_tile = b.tile[chunk_size](tile_id)\n","\n","        # FILL IN (7 lines at most)\n","        @parameter\n","        for i in range(tile_size):\n","          global_start = tile_id * chunk_size + i * simd_width\n","\n","          a_vec = a.load[simd_width](global_start, 0)\n","          b_vec = b.load[simd_width](global_start, 0)\n","\n","          ret = a_vec + b_vec\n","          output.store[simd_width](global_start, 0, ret)\n","\n","    # Number of tiles needed: each tile processes chunk_size elements\n","    num_tiles = (size + chunk_size - 1) // chunk_size\n","    elementwise[\n","        process_manual_vectorized_tiles, num_threads_per_tile, target=\"gpu\"\n","    ](num_tiles, ctx)\n","\n","\n","# ANCHOR_END: manual_vectorized_tiled_elementwise_add\n","\n","\n","# ANCHOR: vectorize_within_tiles_elementwise_add\n","fn vectorize_within_tiles_elementwise_add[\n","    layout: Layout,\n","    dtype: DType,\n","    simd_width: Int,\n","    num_threads_per_tile: Int,\n","    rank: Int,\n","    size: Int,\n","    tile_size: Int,\n","](\n","    output: LayoutTensor[mut=True, dtype, layout, MutableAnyOrigin],\n","    a: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    b: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],\n","    ctx: DeviceContext,\n",") raises:\n","    # Each tile contains tile_size elements (not SIMD groups)\n","    @parameter\n","    @always_inline\n","    fn process_tile_with_vectorize[\n","        num_threads_per_tile: Int, rank: Int, alignment: Int = alignof[dtype]()\n","    ](indices: IndexList[rank]) capturing -> None:\n","        tile_id = indices[0]\n","        tile_start = tile_id * tile_size\n","        tile_end = min(tile_start + tile_size, size)\n","        actual_tile_size = tile_end - tile_start\n","        print(\n","            \"tile_id:\",\n","            tile_id,\n","            \"tile_start:\",\n","            tile_start,\n","            \"tile_end:\",\n","            tile_end,\n","            \"actual_tile_size:\",\n","            actual_tile_size,\n","        )\n","\n","        # FILL IN (9 lines at most)\n","        @parameter\n","        fn vectorized_add[width: Int](i: Int):\n","          global_idx = tile_start + i\n","          if global_idx + width <= size:\n","            a_vec = a.load[width](global_idx, 0)\n","            b_vec = b.load[width](global_idx, 0)\n","            result = a_vec + b_vec\n","            output.store[width](global_idx, 0, result)\n","\n","        vectorize[vectorized_add, simd_width](actual_tile_size)\n","\n","    num_tiles = (size + tile_size - 1) // tile_size\n","    elementwise[\n","        process_tile_with_vectorize, num_threads_per_tile, target=\"gpu\"\n","    ](num_tiles, ctx)\n","\n","\n","# ANCHOR_END: vectorize_within_tiles_elementwise_add\n","\n","\n","@parameter\n","@always_inline\n","fn benchmark_elementwise_parameterized[\n","    test_size: Int, tile_size: Int\n","](mut b: Bencher) raises:\n","    @parameter\n","    @always_inline\n","    fn elementwise_workflow(ctx: DeviceContext) raises:\n","        alias layout = Layout.row_major(test_size)\n","        out = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        a = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        b_buf = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","\n","        with a.map_to_host() as a_host, b_buf.map_to_host() as b_host:\n","            for i in range(test_size):\n","                a_host[i] = 2 * i\n","                b_host[i] = 2 * i + 1\n","\n","        a_tensor = LayoutTensor[mut=False, dtype, layout](a.unsafe_ptr())\n","        b_tensor = LayoutTensor[mut=False, dtype, layout](b_buf.unsafe_ptr())\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","\n","        elementwise_add[layout, dtype, SIMD_WIDTH, rank, test_size](\n","            out_tensor, a_tensor, b_tensor, ctx\n","        )\n","        keep(out.unsafe_ptr())\n","        ctx.synchronize()\n","\n","    bench_ctx = DeviceContext()\n","    b.iter_custom[elementwise_workflow](bench_ctx)\n","\n","\n","@parameter\n","@always_inline\n","fn benchmark_tiled_parameterized[\n","    test_size: Int, tile_size: Int\n","](mut b: Bencher) raises:\n","    @parameter\n","    @always_inline\n","    fn tiled_workflow(ctx: DeviceContext) raises:\n","        alias layout = Layout.row_major(test_size)\n","        out = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        a = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        b_buf = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","\n","        with a.map_to_host() as a_host, b_buf.map_to_host() as b_host:\n","            for i in range(test_size):\n","                a_host[i] = 2 * i\n","                b_host[i] = 2 * i + 1\n","\n","        a_tensor = LayoutTensor[mut=False, dtype, layout](a.unsafe_ptr())\n","        b_tensor = LayoutTensor[mut=False, dtype, layout](b_buf.unsafe_ptr())\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","\n","        tiled_elementwise_add[\n","            layout, dtype, SIMD_WIDTH, rank, test_size, tile_size\n","        ](out_tensor, a_tensor, b_tensor, ctx)\n","        keep(out.unsafe_ptr())\n","        ctx.synchronize()\n","\n","    bench_ctx = DeviceContext()\n","    b.iter_custom[tiled_workflow](bench_ctx)\n","\n","\n","@parameter\n","@always_inline\n","fn benchmark_manual_vectorized_parameterized[\n","    test_size: Int, tile_size: Int\n","](mut b: Bencher) raises:\n","    @parameter\n","    @always_inline\n","    fn manual_vectorized_workflow(ctx: DeviceContext) raises:\n","        alias layout = Layout.row_major(test_size)\n","        out = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        a = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        b_buf = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","\n","        with a.map_to_host() as a_host, b_buf.map_to_host() as b_host:\n","            for i in range(test_size):\n","                a_host[i] = 2 * i\n","                b_host[i] = 2 * i + 1\n","\n","        a_tensor = LayoutTensor[mut=False, dtype, layout](a.unsafe_ptr())\n","        b_tensor = LayoutTensor[mut=False, dtype, layout](b_buf.unsafe_ptr())\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","\n","        manual_vectorized_tiled_elementwise_add[\n","            layout, dtype, SIMD_WIDTH, 1, rank, test_size, tile_size\n","        ](out_tensor, a_tensor, b_tensor, ctx)\n","        keep(out.unsafe_ptr())\n","        ctx.synchronize()\n","\n","    bench_ctx = DeviceContext()\n","    b.iter_custom[manual_vectorized_workflow](bench_ctx)\n","\n","\n","@parameter\n","@always_inline\n","fn benchmark_vectorized_parameterized[\n","    test_size: Int, tile_size: Int\n","](mut b: Bencher) raises:\n","    @parameter\n","    @always_inline\n","    fn vectorized_workflow(ctx: DeviceContext) raises:\n","        alias layout = Layout.row_major(test_size)\n","        out = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        a = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","        b_buf = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)\n","\n","        with a.map_to_host() as a_host, b_buf.map_to_host() as b_host:\n","            for i in range(test_size):\n","                a_host[i] = 2 * i\n","                b_host[i] = 2 * i + 1\n","\n","        a_tensor = LayoutTensor[mut=False, dtype, layout](a.unsafe_ptr())\n","        b_tensor = LayoutTensor[mut=False, dtype, layout](b_buf.unsafe_ptr())\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","\n","        vectorize_within_tiles_elementwise_add[\n","            layout, dtype, SIMD_WIDTH, 1, rank, test_size, tile_size\n","        ](out_tensor, a_tensor, b_tensor, ctx)\n","        keep(out.unsafe_ptr())\n","        ctx.synchronize()\n","\n","    bench_ctx = DeviceContext()\n","    b.iter_custom[vectorized_workflow](bench_ctx)\n","\n","\n","def main():\n","    ctx = DeviceContext()\n","    out = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","    a = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","    b = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","    expected = ctx.enqueue_create_host_buffer[dtype](SIZE).enqueue_fill(0)\n","\n","    with a.map_to_host() as a_host, b.map_to_host() as b_host:\n","        for i in range(SIZE):\n","            a_host[i] = 2 * i\n","            b_host[i] = 2 * i + 1\n","            expected[i] = a_host[i] + b_host[i]\n","\n","    a_tensor = LayoutTensor[mut=False, dtype, layout](a.unsafe_ptr())\n","    b_tensor = LayoutTensor[mut=False, dtype, layout](b.unsafe_ptr())\n","\n","    ctx.synchronize()\n","\n","    print(\"SIZE:\", SIZE)\n","    print(\"simd_width:\", SIMD_WIDTH)\n","\n","    if len(argv()) != 2 or argv()[1] not in [\n","        \"--elementwise\",\n","        \"--tiled\",\n","        \"--manual-vectorized\",\n","        \"--vectorized\",\n","        \"--benchmark\",\n","    ]:\n","        raise Error(\n","            \"Usage: --elementwise | --tiled | --manual-vectorized |\"\n","            \" --vectorized | --benchmark\"\n","        )\n","\n","    if argv()[1] == \"--elementwise\":\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","        elementwise_add[layout, dtype, SIMD_WIDTH, rank, SIZE](\n","            out_tensor, a_tensor, b_tensor, ctx\n","        )\n","\n","        with out.map_to_host() as out_host:\n","            print(\"out:\", out_host)\n","            print(\"expected:\", expected)\n","            for i in range(SIZE):\n","                assert_equal(out_host[i], expected[i])\n","\n","    elif argv()[1] == \"--tiled\":\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","        print(\"tile size:\", TILE_SIZE)\n","        tiled_elementwise_add[layout, dtype, SIMD_WIDTH, rank, SIZE, TILE_SIZE](\n","            out_tensor, a_tensor, b_tensor, ctx\n","        )\n","\n","        with out.map_to_host() as out_host:\n","            print(\"out:\", out_host)\n","            print(\"expected:\", expected)\n","            for i in range(SIZE):\n","                assert_equal(out_host[i], expected[i])\n","\n","    elif argv()[1] == \"--manual-vectorized\":\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","        print(\"tile size:\", TILE_SIZE)\n","        manual_vectorized_tiled_elementwise_add[\n","            layout, dtype, SIMD_WIDTH, 1, rank, SIZE, TILE_SIZE\n","        ](out_tensor, a_tensor, b_tensor, ctx)\n","\n","        with out.map_to_host() as out_host:\n","            print(\"out:\", out_host)\n","            print(\"expected:\", expected)\n","            for i in range(SIZE):\n","                assert_equal(out_host[i], expected[i])\n","\n","    elif argv()[1] == \"--vectorized\":\n","        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())\n","        print(\"tile size:\", TILE_SIZE)\n","        vectorize_within_tiles_elementwise_add[\n","            layout, dtype, SIMD_WIDTH, 1, rank, SIZE, TILE_SIZE\n","        ](out_tensor, a_tensor, b_tensor, ctx)\n","\n","        with out.map_to_host() as out_host:\n","            print(\"out:\", out_host)\n","            print(\"expected:\", expected)\n","            for i in range(SIZE):\n","                assert_equal(out_host[i], expected[i])\n","\n","    elif argv()[1] == \"--benchmark\":\n","        print(\"Running P21 GPU Benchmarks...\")\n","        print(\"SIMD width:\", SIMD_WIDTH)\n","        print(\"-\" * 80)\n","        bench_config = BenchConfig(max_iters=10, min_warmuptime_secs=0.2)\n","        bench = Bench(bench_config)\n","\n","        print(\"Testing SIZE=16, TILE=4\")\n","        bench.bench_function[benchmark_elementwise_parameterized[16, 4]](\n","            BenchId(\"elementwise_16_4\")\n","        )\n","        bench.bench_function[benchmark_tiled_parameterized[16, 4]](\n","            BenchId(\"tiled_16_4\")\n","        )\n","        bench.bench_function[benchmark_manual_vectorized_parameterized[16, 4]](\n","            BenchId(\"manual_vectorized_16_4\")\n","        )\n","        bench.bench_function[benchmark_vectorized_parameterized[16, 4]](\n","            BenchId(\"vectorized_16_4\")\n","        )\n","\n","        print(\"-\" * 80)\n","        print(\"Testing SIZE=128, TILE=16\")\n","        bench.bench_function[benchmark_elementwise_parameterized[128, 16]](\n","            BenchId(\"elementwise_128_16\")\n","        )\n","        bench.bench_function[benchmark_tiled_parameterized[128, 16]](\n","            BenchId(\"tiled_128_16\")\n","        )\n","        bench.bench_function[\n","            benchmark_manual_vectorized_parameterized[128, 16]\n","        ](BenchId(\"manual_vectorized_128_16\"))\n","\n","        print(\"-\" * 80)\n","        print(\"Testing SIZE=128, TILE=16, Vectorize within tiles\")\n","        bench.bench_function[benchmark_vectorized_parameterized[128, 16]](\n","            BenchId(\"vectorized_128_16\")\n","        )\n","\n","        print(\"-\" * 80)\n","        print(\"Testing SIZE=1048576 (1M), TILE=1024\")\n","        bench.bench_function[\n","            benchmark_elementwise_parameterized[1048576, 1024]\n","        ](BenchId(\"elementwise_1M_1024\"))\n","        bench.bench_function[benchmark_tiled_parameterized[1048576, 1024]](\n","            BenchId(\"tiled_1M_1024\")\n","        )\n","        bench.bench_function[\n","            benchmark_manual_vectorized_parameterized[1048576, 1024]\n","        ](BenchId(\"manual_vectorized_1M_1024\"))\n","        bench.bench_function[benchmark_vectorized_parameterized[1048576, 1024]](\n","            BenchId(\"vectorized_1M_1024\")\n","        )\n","\n","        print(bench)\n","        print(\"Benchmarks completed!\")\n","\"\"\""],"metadata":{"id":"f9gidgAzI7iI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_code_to_file(mojo_code, \"/content/mojo-gpu-puzzles/problems/p23/p23.mojo\")"],"metadata":{"id":"JIOqhGlxI9hA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd /content/mojo-gpu-puzzles && uv run poe p23 --benchmark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V24zBMkTI_zQ","executionInfo":{"status":"ok","timestamp":1756666798032,"user_tz":-330,"elapsed":11650,"user":{"displayName":"firoz","userId":"03277806218454595224"}},"outputId":"3535643c-0b8a-48bc-fc5b-675f7a56875d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[37mPoe =>\u001b[0m \u001b[94mmojo problems/p23/p23.mojo --benchmark\u001b[0m\n","\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:20:67: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mUse `sys.simd_width_of()` instead.\n","\u001b[0malias SIMD_WIDTH = simdwidthof[Float32, target = get_gpu_target()]()\n","\u001b[0;1;32m                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:1:1: \u001b[0m\u001b[0;1;30mnote: \u001b[0m\u001b[1m'simdwidthof' declared here\n","\u001b[0m\n","\u001b[0;1;32m^\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:34:68: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mUse `sys.align_of()` instead.\n","\u001b[0m        simd_width: Int, rank: Int, alignment: Int = alignof[dtype]()\n","\u001b[0;1;32m                                                     ~~~~~~~~~~~~~~^~\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:1:1: \u001b[0m\u001b[0;1;30mnote: \u001b[0m\u001b[1m'alignof' declared here\n","\u001b[0m\n","\u001b[0;1;32m^\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:69:68: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mUse `sys.align_of()` instead.\n","\u001b[0m        simd_width: Int, rank: Int, alignment: Int = alignof[dtype]()\n","\u001b[0;1;32m                                                     ~~~~~~~~~~~~~~^~\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:1:1: \u001b[0m\u001b[0;1;30mnote: \u001b[0m\u001b[1m'alignof' declared here\n","\u001b[0m\n","\u001b[0;1;32m^\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:112:78: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mUse `sys.align_of()` instead.\n","\u001b[0m        num_threads_per_tile: Int, rank: Int, alignment: Int = alignof[dtype]()\n","\u001b[0;1;32m                                                               ~~~~~~~~~~~~~~^~\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:1:1: \u001b[0m\u001b[0;1;30mnote: \u001b[0m\u001b[1m'alignof' declared here\n","\u001b[0m\n","\u001b[0;1;32m^\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:160:78: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mUse `sys.align_of()` instead.\n","\u001b[0m        num_threads_per_tile: Int, rank: Int, alignment: Int = alignof[dtype]()\n","\u001b[0;1;32m                                                               ~~~~~~~~~~~~~~^~\n","\u001b[0m\u001b[1m/content/mojo-gpu-puzzles/problems/p23/p23.mojo:1:1: \u001b[0m\u001b[0;1;30mnote: \u001b[0m\u001b[1m'alignof' declared here\n","\u001b[0m\n","\u001b[0;1;32m^\n","\u001b[0mSIZE: 1024\n","simd_width: 4\n","Running P21 GPU Benchmarks...\n","SIMD width: 4\n","--------------------------------------------------------------------------------\n","Testing SIZE=16, TILE=4\n","Running elementwise_16_4\n","stack trace was not collected. Enable stack trace collection with environment variable `MOJO_ENABLE_STACK_TRACE_ON_ERROR`\n","Unhandled exception caught during execution: At open-source/max/mojo/stdlib/stdlib/benchmark/benchmark.mojo:577:17: AssertionError: `left == right` comparison failed:\n","   left: 200000000\n","  right: 0\n","  reason: ERROR: min_warmup_time will be removed in near future. Consider using num_warmup_iters\n","/content/mojo-gpu-puzzles/.venv/bin/mojo: error: execution exited with a non-zero result: 1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"817dPco8JBIJ"},"execution_count":null,"outputs":[]}]}