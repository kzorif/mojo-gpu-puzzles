{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyONSqKzjXZ1weRA/atjAkwd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCmO2kesC3LB","executionInfo":{"status":"ok","timestamp":1756560401992,"user_tz":-330,"elapsed":22746,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"f1472b16-ae11-4a47-eb99-acd21c93150f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n","Collecting max==25.4.0\n","  Downloading https://dl.modular.com/public/nightly/python/max-25.4.0-py3-none-manylinux_2_34_x86_64.whl (285.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.0/285.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (8.2.1)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (2.0.2)\n","Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (4.67.1)\n","Installing collected packages: max\n","Successfully installed max-25.4.0\n"]}],"source":["!pip install max==25.4.0 --index-url https://dl.modular.com/public/nightly/python/simple/"]},{"cell_type":"code","source":["!git clone https://github.com/modular/mojo-gpu-puzzles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U0QG4W_uC5YI","executionInfo":{"status":"ok","timestamp":1756560410435,"user_tz":-330,"elapsed":8438,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"555afa0f-9656-4dec-db16-222694132ab7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mojo-gpu-puzzles'...\n","remote: Enumerating objects: 6332, done.\u001b[K\n","remote: Counting objects: 100% (481/481), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 6332 (delta 449), reused 416 (delta 416), pack-reused 5851 (from 3)\u001b[K\n","Receiving objects: 100% (6332/6332), 148.64 MiB | 30.80 MiB/s, done.\n","Resolving deltas: 100% (3923/3923), done.\n"]}]},{"cell_type":"code","source":["!curl -fsSL https://astral.sh/uv/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UTNpkO4C9az","executionInfo":{"status":"ok","timestamp":1756560412006,"user_tz":-330,"elapsed":1573,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"3d5263c7-4f63-4d16-eeac-9dced66f6587"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.8.14 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}]},{"cell_type":"code","source":["import max.support.notebook"],"metadata":{"id":"7HRKgbwkC_GW","executionInfo":{"status":"ok","timestamp":1756560412052,"user_tz":-330,"elapsed":33,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def save_code_to_file(text: str, filename: str):\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)"],"metadata":{"id":"k2ZvVs8GDBGJ","executionInfo":{"status":"ok","timestamp":1756560412053,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mojo_code = \"\"\"\n","from typing import Optional\n","from pathlib import Path\n","import numpy as np\n","# ANCHOR: conv1d_pytorch\n","import torch\n","from max.torch import CustomOpLibrary\n","\n","\n","def conv1d_pytorch(input_tensor: torch.Tensor, kernel_tensor: torch.Tensor) -> torch.Tensor:\n","    # Load our custom operations\n","    mojo_kernels = Path(__file__).parent / \"op\"\n","    ops = CustomOpLibrary(mojo_kernels)\n","\n","    # Create output tensor with same shape as input\n","    output_tensor = torch.empty_like(input_tensor)\n","\n","    # Call our custom conv1d operation with explicit output tensor\n","    # The Mojo signature expects: (out, input, kernel)\n","    conv1d = ops.conv1d[{\"input_size\": input_tensor.shape[0], \"conv_size\": kernel_tensor.shape[0]}]\n","\n","    # FILL IN with 1 line of code\n","    torch.compile(conv1d)(output_tensor, input_tensor, kernel_tensor)\n","    return output_tensor\n","\n","# ANCHOR_END: conv1d_pytorch\n","\n","def conv1d_max_graph_reference(\n","    input_array: np.ndarray,\n","    kernel_array: np.ndarray,\n","    device: Optional[str] = None\n",") -> np.ndarray:\n","    from max.driver import CPU, Accelerator, Tensor, accelerator_count\n","    from max.dtype import DType\n","    from max.engine import InferenceSession\n","    from max.graph import DeviceRef, Graph, TensorType, ops\n","\n","    # Use the same device logic as p15\n","    if device is None:\n","        device_obj = CPU() if accelerator_count() == 0 else Accelerator()\n","    else:\n","        device_obj = CPU() if device == \"cpu\" else Accelerator()\n","\n","    session = InferenceSession(devices=[device_obj])\n","\n","    # Convert to MAX Graph tensors\n","    input_tensor = Tensor.from_numpy(input_array).to(device_obj)\n","    kernel_tensor = Tensor.from_numpy(kernel_array).to(device_obj)\n","\n","    # Same graph setup as p15\n","    with Graph(\n","        \"conv_1d_reference_graph\",\n","        input_types=[\n","            TensorType(DType.float32, shape=input_tensor.shape, device=DeviceRef.from_device(device_obj)),\n","            TensorType(DType.float32, shape=kernel_tensor.shape, device=DeviceRef.from_device(device_obj)),\n","        ],\n","        custom_extensions=[Path(__file__).parent / \"op\"],\n","    ) as graph:\n","        input_value, kernel_value = graph.inputs\n","        output = ops.custom(\n","            name=\"conv1d\",\n","            values=[input_value, kernel_value],\n","            device=DeviceRef.from_device(device_obj),\n","            out_types=[TensorType(\n","                dtype=input_value.tensor.dtype,\n","                shape=input_value.tensor.shape,\n","                device=DeviceRef.from_device(device_obj),\n","            )],\n","            parameters={\n","                \"input_size\": input_tensor.shape[0],\n","                \"conv_size\": kernel_tensor.shape[0],\n","                \"dtype\": DType.float32,\n","            },\n","        )[0].tensor\n","        graph.output(output)\n","\n","    model = session.load(graph)\n","    result = model.execute(input_tensor, kernel_tensor)[0]\n","    return result.to(CPU()).to_numpy()\n","\n","\n","def compute_numpy_reference(input_array: np.ndarray, kernel_array: np.ndarray) -> np.ndarray:\n","    INPUT_SIZE = len(input_array)\n","    KERNEL_SIZE = len(kernel_array)\n","\n","    expected_result = np.zeros_like(input_array, dtype=np.float32)\n","    for i in range(INPUT_SIZE):\n","        for j in range(KERNEL_SIZE):\n","            if i + j < INPUT_SIZE:\n","                expected_result[i] += input_array[i + j] * kernel_array[j]\n","    return expected_result\n","\n","\n","if __name__ == \"__main__\":\n","    INPUT_SIZE = 15\n","    KERNEL_SIZE = 4\n","\n","    # Create test data (same as p15 for easy comparison)\n","    input_array = np.arange(INPUT_SIZE, dtype=np.float32)\n","    kernel_array = np.arange(KERNEL_SIZE, dtype=np.float32)\n","\n","    print(\"Puzzle 18: From MAX Graph to PyTorch Custom Ops\")\n","    print(\"=\" * 60)\n","    print(f\"Input array: {input_array}\")\n","    print(f\"Convolution kernel: {kernel_array}\")\n","    print()\n","\n","    numpy_result = compute_numpy_reference(input_array, kernel_array)\n","    print(f\"NumPy reference result: {numpy_result}\")\n","    print()\n","\n","    device = \"cuda\"\n","    input_tensor = torch.from_numpy(input_array).to(device)\n","    kernel_tensor = torch.from_numpy(kernel_array).to(device)\n","\n","    print(f\"Testing PyTorch Custom Op (device: {device})\")\n","    print(\"-\" * 40)\n","\n","    try:\n","        pytorch_result = conv1d_pytorch(input_tensor, kernel_tensor)\n","        pytorch_result_cpu = pytorch_result.cpu().numpy()\n","        print(f\"PyTorch custom op result: {pytorch_result_cpu}\")\n","\n","        # Verify PyTorch result\n","        np.testing.assert_allclose(pytorch_result_cpu, numpy_result, rtol=1e-5)\n","        print(\"✅ PyTorch custom op verification PASSED\")\n","\n","    except Exception as e:\n","        print(f\"❌ PyTorch custom op failed: {e}\")\n","        pytorch_result_cpu = None\n","\n","    print()\n","\n","    # Compare with MAX Graph approach (like p15)\n","    print(\"Comparing with MAX Graph approach (like p15)\")\n","    print(\"-\" * 40)\n","\n","    try:\n","        max_graph_result = conv1d_max_graph_reference(input_array, kernel_array)\n","        print(f\"MAX Graph result: {max_graph_result}\")\n","\n","        # Verify MAX Graph result\n","        np.testing.assert_allclose(max_graph_result, numpy_result, rtol=1e-5)\n","        print(\"✅ MAX Graph verification PASSED\")\n","\n","        if pytorch_result_cpu is not None:\n","            np.testing.assert_allclose(pytorch_result_cpu, max_graph_result, rtol=1e-5)\n","            print(\"✅ PyTorch and MAX Graph results MATCH\")\n","\n","    except Exception as e:\n","        print(f\"❌ MAX Graph comparison failed: {e}\")\n","\n","    print()\n","    print(\"Key Learning Points:\")\n","    print(\"• Same Mojo kernel works for both MAX Graph and PyTorch\")\n","    print(\"• PyTorch CustomOpLibrary requires explicit output tensor allocation\")\n","    print(\"• Both approaches call the exact same optimized GPU kernel\")\n","    print(\"• PyTorch tensors can stay on GPU throughout the computation\")\n","\"\"\""],"metadata":{"id":"v1eoNtAaDC5g","executionInfo":{"status":"ok","timestamp":1756560412081,"user_tz":-330,"elapsed":31,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["save_code_to_file(mojo_code, \"/content/mojo-gpu-puzzles/problems/p20/p20.py\")"],"metadata":{"id":"umyjBD6VDIZb","executionInfo":{"status":"ok","timestamp":1756560412084,"user_tz":-330,"elapsed":2,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!cd /content/mojo-gpu-puzzles && uv run poe p20"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-IgUTyUuDIbP","executionInfo":{"status":"ok","timestamp":1756560518186,"user_tz":-330,"elapsed":106097,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"b6762524-fc64-451b-feb8-91ab76107613"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CPython 3.12.11 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n","Creating virtual environment at: \u001b[36m.venv\u001b[39m\n","\u001b[2K\u001b[2mInstalled \u001b[1m32 packages\u001b[0m \u001b[2min 416ms\u001b[0m\u001b[0m\n","\u001b[37mPoe =>\u001b[0m \u001b[94mpython problems/p20/p20.py\u001b[0m\n","Puzzle 18: From MAX Graph to PyTorch Custom Ops\n","============================================================\n","Input array: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n","Convolution kernel: [0. 1. 2. 3.]\n","\n","NumPy reference result: [14. 20. 26. 32. 38. 44. 50. 56. 62. 68. 74. 80. 41. 14.  0.]\n","\n","Testing PyTorch Custom Op (device: cuda)\n","----------------------------------------\n","ERROR:root:Error compiling Mojo at /content/mojo-gpu-puzzles/problems/p20/op. Command: package /content/mojo-gpu-puzzles/problems/p20/op -o /tmp/.modular/mojo_pkg/mojo_pkg_6c850c04a716713d3b3f9f3497021235.mojopkg\n","\n","Included from /content/mojo-gpu-puzzles/problems/p20/op/__init__.mojo:1:\n","/content/mojo-gpu-puzzles/problems/p20/op/conv1d.mojo:6:17: error: package 'sys' does not contain 'sizeof'\n","from sys import sizeof, argv\n","                ^\n","/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/modular/bin/mojo: error: failed to parse the provided Mojo source module\n","\n","❌ PyTorch custom op failed: Error compiling Mojo at /content/mojo-gpu-puzzles/problems/p20/op. Command: package /content/mojo-gpu-puzzles/problems/p20/op -o /tmp/.modular/mojo_pkg/mojo_pkg_6c850c04a716713d3b3f9f3497021235.mojopkg\n","\n","Included from /content/mojo-gpu-puzzles/problems/p20/op/__init__.mojo:1:\n","/content/mojo-gpu-puzzles/problems/p20/op/conv1d.mojo:6:17: error: package 'sys' does not contain 'sizeof'\n","from sys import sizeof, argv\n","                ^\n","/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/modular/bin/mojo: error: failed to parse the provided Mojo source module\n","\n","\n","Comparing with MAX Graph approach (like p15)\n","----------------------------------------\n","ERROR:root:Error compiling Mojo at /content/mojo-gpu-puzzles/problems/p20/op. Command: package /content/mojo-gpu-puzzles/problems/p20/op -o /tmp/.modular/mojo_pkg/mojo_pkg_6c850c04a716713d3b3f9f3497021235.mojopkg\n","\n","Included from /content/mojo-gpu-puzzles/problems/p20/op/__init__.mojo:1:\n","/content/mojo-gpu-puzzles/problems/p20/op/conv1d.mojo:6:17: error: package 'sys' does not contain 'sizeof'\n","from sys import sizeof, argv\n","                ^\n","/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/modular/bin/mojo: error: failed to parse the provided Mojo source module\n","\n","❌ MAX Graph comparison failed: Error compiling Mojo at /content/mojo-gpu-puzzles/problems/p20/op. Command: package /content/mojo-gpu-puzzles/problems/p20/op -o /tmp/.modular/mojo_pkg/mojo_pkg_6c850c04a716713d3b3f9f3497021235.mojopkg\n","\n","Included from /content/mojo-gpu-puzzles/problems/p20/op/__init__.mojo:1:\n","/content/mojo-gpu-puzzles/problems/p20/op/conv1d.mojo:6:17: error: package 'sys' does not contain 'sizeof'\n","from sys import sizeof, argv\n","                ^\n","/content/mojo-gpu-puzzles/.venv/lib/python3.12/site-packages/modular/bin/mojo: error: failed to parse the provided Mojo source module\n","\n","\n","Key Learning Points:\n","• Same Mojo kernel works for both MAX Graph and PyTorch\n","• PyTorch CustomOpLibrary requires explicit output tensor allocation\n","• Both approaches call the exact same optimized GPU kernel\n","• PyTorch tensors can stay on GPU throughout the computation\n"]}]},{"cell_type":"code","source":["!uv run mojo --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJlz0795DIdZ","executionInfo":{"status":"ok","timestamp":1756560518897,"user_tz":-330,"elapsed":717,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"fe8c873d-cc9f-4def-a24f-ae7a704ed26d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mojo 25.4.0 (fbeca2fa)\n"]}]},{"cell_type":"code","source":["cat /etc/os-release"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyfpxOFyItxS","executionInfo":{"status":"ok","timestamp":1756560518992,"user_tz":-330,"elapsed":93,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"da88db3d-f359-4d7b-b824-25aa443bb5c6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["PRETTY_NAME=\"Ubuntu 22.04.4 LTS\"\n","NAME=\"Ubuntu\"\n","VERSION_ID=\"22.04\"\n","VERSION=\"22.04.4 LTS (Jammy Jellyfish)\"\n","VERSION_CODENAME=jammy\n","ID=ubuntu\n","ID_LIKE=debian\n","HOME_URL=\"https://www.ubuntu.com/\"\n","SUPPORT_URL=\"https://help.ubuntu.com/\"\n","BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n","PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n","UBUNTU_CODENAME=jammy\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6ad2F8nNJBAn","executionInfo":{"status":"ok","timestamp":1756560519032,"user_tz":-330,"elapsed":38,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":10,"outputs":[]}]}