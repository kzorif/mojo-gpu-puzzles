{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNqjGHwXZ4FhUq028SUoHED"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRNNccmw3esG","executionInfo":{"status":"ok","timestamp":1753555714716,"user_tz":-330,"elapsed":22773,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"0cf69bfb-70b8-45c9-9a81-5a0f77614792"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n","Collecting max\n","  Downloading https://dl.modular.com/public/nightly/python/max-25.4.0-py3-none-manylinux_2_34_x86_64.whl (285.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.0/285.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from max) (8.2.1)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from max) (2.0.2)\n","Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.11/dist-packages (from max) (4.67.1)\n","Installing collected packages: max\n","Successfully installed max-25.4.0\n"]}],"source":["!pip install max --index-url https://dl.modular.com/public/nightly/python/simple/"]},{"cell_type":"code","source":["!git clone https://github.com/modular/mojo-gpu-puzzles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrTD4Rez7lDZ","executionInfo":{"status":"ok","timestamp":1753555723382,"user_tz":-330,"elapsed":8664,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"de51bd2d-029a-4d25-99d7-3da82d0b57ce"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mojo-gpu-puzzles'...\n","remote: Enumerating objects: 5629, done.\u001b[K\n","remote: Counting objects: 100% (748/748), done.\u001b[K\n","remote: Compressing objects: 100% (230/230), done.\u001b[K\n","remote: Total 5629 (delta 613), reused 588 (delta 497), pack-reused 4881 (from 2)\u001b[K\n","Receiving objects: 100% (5629/5629), 100.81 MiB | 16.41 MiB/s, done.\n","Resolving deltas: 100% (3525/3525), done.\n"]}]},{"cell_type":"code","source":["!curl -fsSL https://astral.sh/uv/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6FuNNS37mNl","executionInfo":{"status":"ok","timestamp":1753555724987,"user_tz":-330,"elapsed":1603,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"61009799-ed18-4df9-f3d4-9447031f993b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.8.3 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}]},{"cell_type":"code","source":["import max.support.notebook"],"metadata":{"id":"3DY9uwRu7nVM","executionInfo":{"status":"ok","timestamp":1753555725018,"user_tz":-330,"elapsed":19,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def save_code_to_file(text: str, filename: str):\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)"],"metadata":{"id":"s00YV9cz7odF","executionInfo":{"status":"ok","timestamp":1753555725020,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["mojo_code = \"\"\"\n","from gpu import thread_idx, block_idx, block_dim, barrier\n","from gpu.host import DeviceContext\n","from layout import Layout, LayoutTensor\n","from layout.tensor_builder import LayoutTensorBuild as tb\n","from sys import sizeof, argv\n","from testing import assert_equal\n","\n","# ANCHOR: conv_1d_simple\n","alias TPB = 8\n","alias SIZE = 6\n","alias CONV = 3\n","alias BLOCKS_PER_GRID = (1, 1)\n","alias THREADS_PER_BLOCK = (TPB, 1)\n","alias dtype = DType.float32\n","alias in_layout = Layout.row_major(SIZE)\n","alias out_layout = Layout.row_major(SIZE)\n","alias conv_layout = Layout.row_major(CONV)\n","\n","\n","fn conv_1d_simple[\n","    in_layout: Layout, out_layout: Layout, conv_layout: Layout\n","](\n","    output: LayoutTensor[mut=False, dtype, out_layout],\n","    a: LayoutTensor[mut=False, dtype, in_layout],\n","    b: LayoutTensor[mut=False, dtype, conv_layout],\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","    local_i = thread_idx.x\n","    ################################# SIMPLE CASE #######################################################\n","    shared_a = tb[dtype]().row_major[TPB]().shared().alloc()\n","    shared_b = tb[dtype]().row_major[TPB]().shared().alloc()\n","\n","    if global_i < SIZE:\n","      shared_a[global_i] = a[global_i]\n","    else:\n","      shared_a[local_i] = 0\n","\n","    if global_i < CONV:\n","      shared_b[local_i] = b[global_i]\n","\n","    barrier()\n","\n","    # actual logic here ####\n","    if global_i < SIZE:\n","      var local_sum: output.element_type = 0\n","\n","      @parameter\n","      for j in range(CONV):\n","        if local_i + j < SIZE:\n","          local_sum += shared_a[local_i + j] * shared_b[j]\n","\n","      output[global_i] = local_sum\n","\n","\n","# ANCHOR_END: conv_1d_simple\n","\n","# ANCHOR: conv_1d_block_boundary\n","alias SIZE_2 = 15\n","alias CONV_2 = 4\n","alias BLOCKS_PER_GRID_2 = (2, 1)\n","alias THREADS_PER_BLOCK_2 = (TPB, 1)\n","alias in_2_layout = Layout.row_major(SIZE_2)\n","alias out_2_layout = Layout.row_major(SIZE_2)\n","alias conv_2_layout = Layout.row_major(CONV_2)\n","\n","\n","fn conv_1d_block_boundary[\n","    in_layout: Layout, out_layout: Layout, conv_layout: Layout, dtype: DType\n","](\n","    output: LayoutTensor[mut=False, dtype, out_layout],\n","    a: LayoutTensor[mut=False, dtype, in_layout],\n","    b: LayoutTensor[mut=False, dtype, conv_layout],\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","    local_i = thread_idx.x\n","  ####################                BLOCK BOUNDARY                  ###################\n","    # FILL ME IN (roughly 18 lines)\n","    shared_a = tb[dtype]().row_major[TPB + CONV_2 - 1]().shared().alloc()\n","    shared_b = tb[dtype]().row_major[CONV_2]().shared().alloc()\n","\n","    if global_i < SIZE_2:\n","      shared_a[local_i] = a[global_i]\n","    else:\n","      shared_a[local_i] = 0\n","\n","    if local_i < CONV_2 - 1:\n","      next_idx = global_i + TPB\n","      if next_idx < SIZE_2:\n","        shared_a[TPB + local_i] = a[next_idx]\n","      else:\n","        shared_a[TPB + local_i] = 0\n","\n","\n","    if local_i < CONV_2:\n","      shared_b[local_i] = b[local_i]\n","\n","    barrier()\n","\n","    if global_i < SIZE_2:\n","      var local_sum: output.element_type = 0\n","\n","      @parameter\n","      for j in range(CONV_2):\n","        if global_i + j < SIZE_2:\n","          local_sum += shared_a[local_i+j] * shared_b[j]\n","\n","      output[global_i] = local_sum\n","\n","# ANCHOR_END: conv_1d_block_boundary\n","\n","\n","def main():\n","    with DeviceContext() as ctx:\n","        size = SIZE_2 if argv()[1] == \"--block-boundary\" else SIZE\n","        conv = CONV_2 if argv()[1] == \"--block-boundary\" else CONV\n","        out = ctx.enqueue_create_buffer[dtype](size).enqueue_fill(0)\n","        a = ctx.enqueue_create_buffer[dtype](size).enqueue_fill(0)\n","        b = ctx.enqueue_create_buffer[dtype](conv).enqueue_fill(0)\n","        with a.map_to_host() as a_host:\n","            for i in range(size):\n","                a_host[i] = i\n","\n","        with b.map_to_host() as b_host:\n","            for i in range(conv):\n","                b_host[i] = i\n","\n","        if argv()[1] == \"--simple\":\n","            var out_tensor = LayoutTensor[mut=False, dtype, out_layout](\n","                out.unsafe_ptr()\n","            )\n","            var a_tensor = LayoutTensor[mut=False, dtype, in_layout](\n","                a.unsafe_ptr()\n","            )\n","            var b_tensor = LayoutTensor[mut=False, dtype, conv_layout](\n","                b.unsafe_ptr()\n","            )\n","            ctx.enqueue_function[\n","                conv_1d_simple[in_layout, out_layout, conv_layout]\n","            ](\n","                out_tensor,\n","                a_tensor,\n","                b_tensor,\n","                grid_dim=BLOCKS_PER_GRID,\n","                block_dim=THREADS_PER_BLOCK,\n","            )\n","        elif argv()[1] == \"--block-boundary\":\n","            var out_tensor = LayoutTensor[mut=False, dtype, out_2_layout](\n","                out.unsafe_ptr()\n","            )\n","            var a_tensor = LayoutTensor[mut=False, dtype, in_2_layout](\n","                a.unsafe_ptr()\n","            )\n","            var b_tensor = LayoutTensor[mut=False, dtype, conv_2_layout](\n","                b.unsafe_ptr()\n","            )\n","            ctx.enqueue_function[\n","                conv_1d_block_boundary[\n","                    in_2_layout, out_2_layout, conv_2_layout, dtype\n","                ]\n","            ](\n","                out_tensor,\n","                a_tensor,\n","                b_tensor,\n","                grid_dim=BLOCKS_PER_GRID_2,\n","                block_dim=THREADS_PER_BLOCK_2,\n","            )\n","        else:\n","            raise Error(\"Invalid argument\")\n","\n","        ctx.synchronize()\n","        expected = ctx.enqueue_create_host_buffer[dtype](size).enqueue_fill(0)\n","\n","        with a.map_to_host() as a_host, b.map_to_host() as b_host:\n","            for i in range(size):\n","                for j in range(conv):\n","                    if i + j < size:\n","                        expected[i] += a_host[i + j] * b_host[j]\n","\n","        with out.map_to_host() as out_host:\n","            print(\"out:\", out_host)\n","            print(\"expected:\", expected)\n","            for i in range(size):\n","                assert_equal(out_host[i], expected[i])\n","\n","\n","\"\"\""],"metadata":{"id":"4RcnVFL_7pmO","executionInfo":{"status":"ok","timestamp":1753556616159,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["save_code_to_file(mojo_code, \"/content/mojo-gpu-puzzles/problems/p11/p11.mojo\")"],"metadata":{"id":"AgCpnUgK7tYs","executionInfo":{"status":"ok","timestamp":1753556616459,"user_tz":-330,"elapsed":2,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["!cd /content/mojo-gpu-puzzles && uv run poe p11 --block-boundary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TddYSuGQ7tap","executionInfo":{"status":"ok","timestamp":1753556629738,"user_tz":-330,"elapsed":12632,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"19d7c2c1-c9ba-4d4b-a59e-27829d108651"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[37mPoe =>\u001b[0m \u001b[94mmojo problems/p11/p11.mojo --block-boundary\u001b[0m\n","out: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])\n","expected: HostBuffer([14.0, 20.0, 26.0, 32.0, 38.0, 44.0, 50.0, 56.0, 62.0, 68.0, 74.0, 80.0, 41.0, 14.0, 0.0])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JJiMn_fH7tcZ","executionInfo":{"status":"ok","timestamp":1753555833564,"user_tz":-330,"elapsed":2,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mQ8i1-Vm7tej","executionInfo":{"status":"ok","timestamp":1753555833565,"user_tz":-330,"elapsed":1,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":9,"outputs":[]}]}