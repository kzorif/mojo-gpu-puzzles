{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMRQga0U68wjU/5rtjl+Beh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKfRh2mXo5I1","executionInfo":{"status":"ok","timestamp":1756807573538,"user_tz":-330,"elapsed":24674,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"d32246ff-e7f2-4d41-f7ea-0c1fa8eff88c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n","Collecting max==25.4.0\n","  Downloading https://dl.modular.com/public/nightly/python/max-25.4.0-py3-none-manylinux_2_34_x86_64.whl (285.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.0/285.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (8.2.1)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (2.0.2)\n","Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (4.67.1)\n","Installing collected packages: max\n","Successfully installed max-25.4.0\n"]}],"source":["!pip install max==25.4.0 --index-url https://dl.modular.com/public/nightly/python/simple/"]},{"cell_type":"code","source":["!git clone https://github.com/modular/mojo-gpu-puzzles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkasrJEJo8Rc","executionInfo":{"status":"ok","timestamp":1756807583125,"user_tz":-330,"elapsed":9577,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"cbaa24b7-bcd2-466e-9461-adc4f3565b38"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mojo-gpu-puzzles'...\n","remote: Enumerating objects: 6332, done.\u001b[K\n","remote: Counting objects: 100% (481/481), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 6332 (delta 449), reused 416 (delta 416), pack-reused 5851 (from 3)\u001b[K\n","Receiving objects: 100% (6332/6332), 148.64 MiB | 23.40 MiB/s, done.\n","Resolving deltas: 100% (3923/3923), done.\n"]}]},{"cell_type":"code","source":["!curl -fsSL https://astral.sh/uv/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AUP6d5FrKzX","executionInfo":{"status":"ok","timestamp":1756807585076,"user_tz":-330,"elapsed":1949,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"c3bbe047-0f01-4b3e-95b8-50b7b9cf3369"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.8.14 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}]},{"cell_type":"code","source":["import max.support.notebook"],"metadata":{"id":"9kB7AfABr6YY","executionInfo":{"status":"ok","timestamp":1756807585092,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def save_code_to_file(text: str, filename: str):\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)"],"metadata":{"id":"eITve3mgr8K9","executionInfo":{"status":"ok","timestamp":1756807585101,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mojo_code = \"\"\"\n","from gpu import thread_idx, block_idx, block_dim, lane_id\n","from gpu.host import DeviceContext\n","from gpu.warp import shuffle_xor, prefix_sum, WARP_SIZE\n","from layout import Layout, LayoutTensor\n","from sys import argv\n","from testing import assert_equal, assert_almost_equal\n","\n","# ANCHOR: butterfly_pair_swap\n","alias SIZE = WARP_SIZE\n","alias BLOCKS_PER_GRID = (1, 1)\n","alias THREADS_PER_BLOCK = (WARP_SIZE, 1)\n","alias dtype = DType.float32\n","alias layout = Layout.row_major(SIZE)\n","\n","\n","fn butterfly_pair_swap[\n","    layout: Layout, size: Int\n","](\n","    output: LayoutTensor[mut=False, dtype, layout],\n","    input: LayoutTensor[mut=False, dtype, layout],\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","\n","    # FILL ME IN (4 lines)\n","    if global_i < size:\n","        current_val = input[global_i]\n","        swapped_val = shuffle_xor(current_val, 1)\n","        output[global_i] = swapped_val\n","\n","# ANCHOR_END: butterfly_pair_swap\n","\n","\n","# ANCHOR: butterfly_parallel_max\n","fn butterfly_parallel_max[\n","    layout: Layout, size: Int\n","](\n","    output: LayoutTensor[mut=False, dtype, layout],\n","    input: LayoutTensor[mut=False, dtype, layout],\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","\n","    # FILL ME IN (roughly 7 lines)\n","    if global_i < size:\n","        max_val = input[global_i]\n","        offset = WARP_SIZE // 2\n","        while offset > 0:\n","            max_val = max(max_val, shuffle_xor(max_val, offset))\n","            offset //= 2\n","\n","        output[global_i] = max_val\n","\n","# ANCHOR_END: butterfly_parallel_max\n","\n","\n","# ANCHOR: butterfly_conditional_max\n","alias SIZE_2 = 64\n","alias BLOCKS_PER_GRID_2 = (2, 1)\n","alias THREADS_PER_BLOCK_2 = (WARP_SIZE, 1)\n","alias layout_2 = Layout.row_major(SIZE_2)\n","\n","\n","fn butterfly_conditional_max[\n","    layout: Layout, size: Int\n","](\n","    output: LayoutTensor[mut=False, dtype, layout],\n","    input: LayoutTensor[mut=False, dtype, layout],\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","    lane = lane_id()\n","\n","    if global_i < size:\n","        current_val = input[global_i]\n","        min_val = current_val\n","\n","        # FILL ME IN (roughly 11 lines)\n","        offset = WARP_SIZE // 2\n","        while offset > 0:\n","            neighbor_val = shuffle_xor(current_val, offset)\n","            current_val = max(current_val, neighbor_val)\n","\n","            min_neighbor_val = shuffle_xor(min_val, offset)\n","            min_val = min(min_val, min_neighbor_val)\n","\n","            offset //= 2\n","        if lane % 2 == 0:\n","            output[global_i] = current_val\n","        else:\n","            output[global_i] = min_val\n","\n","\n","# ANCHOR_END: butterfly_conditional_max\n","\n","\n","# ANCHOR: warp_inclusive_prefix_sum\n","fn warp_inclusive_prefix_sum[\n","    layout: Layout, size: Int\n","](\n","    output: LayoutTensor[mut=False, dtype, layout],\n","    input: LayoutTensor[mut=False, dtype, layout],\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","\n","    # FILL ME IN (roughly 4 lines)\n","    if global_i < size:\n","        current_val = input[global_i]\n","        scan_result = prefix_sum[exclusive=False](\n","            rebind[Scalar[dtype]](current_val)\n","        )\n","\n","        output[global_i] = scan_result\n","\n","\n","\n","# ANCHOR_END: warp_inclusive_prefix_sum\n","\n","\n","# ANCHOR: warp_partition\n","fn warp_partition[\n","    layout: Layout, size: Int\n","](\n","    output: LayoutTensor[mut=False, dtype, layout],\n","    input: LayoutTensor[mut=False, dtype, layout],\n","    pivot: Float32,\n","):\n","    global_i = block_dim.x * block_idx.x + thread_idx.x\n","\n","    if global_i < size:\n","        current_val = input[global_i]\n","\n","        # FILL ME IN (roughly 13 lines)\n","        if global_i < size:\n","            current_val = input[global_i]\n","            predicate_left = Float32(1.0) if current_val < pivot else Float32(0.0)\n","            predicate_right = Float32(1.0) if current_val >= pivot else Float32(0.0)\n","\n","            warp_left_pos = prefix_sum[exclusive=True](predicate_left)\n","            warp_right_pos = prefix_sum[exclusive=True](predicate_right)\n","\n","            warp_left_total = predicate_left\n","\n","            offset = WARP_SIZE // 2\n","            while offset > 0:\n","                warp_left_total += shuffle_xor(warp_left_total, offset)\n","                offset //= 2\n","\n","            if current_val < pivot:\n","                output[Int(warp_left_pos)] = current_val\n","            else:\n","                output[Int(warp_left_total + warp_right_pos)] = current_val\n","\n","\n","# ANCHOR_END: warp_partition\n","\n","\n","def test_butterfly_pair_swap():\n","    with DeviceContext() as ctx:\n","        input_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","        output_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","\n","        with input_buf.map_to_host() as input_host:\n","            for i in range(SIZE):\n","                input_host[i] = i\n","\n","        input_tensor = LayoutTensor[mut=False, dtype, layout](\n","            input_buf.unsafe_ptr()\n","        )\n","        output_tensor = LayoutTensor[mut=False, dtype, layout](\n","            output_buf.unsafe_ptr()\n","        )\n","\n","        ctx.enqueue_function[butterfly_pair_swap[layout, SIZE]](\n","            output_tensor,\n","            input_tensor,\n","            grid_dim=BLOCKS_PER_GRID,\n","            block_dim=THREADS_PER_BLOCK,\n","        )\n","\n","        expected_buf = ctx.enqueue_create_host_buffer[dtype](SIZE).enqueue_fill(\n","            0\n","        )\n","        ctx.synchronize()\n","\n","        # Create expected results: pairs should be swapped\n","        # (0,1) -> (1,0), (2,3) -> (3,2), (4,5) -> (5,4), etc.\n","        for i in range(SIZE):\n","            if i % 2 == 0:\n","                # Even positions get odd values\n","                expected_buf[i] = i + 1\n","            else:\n","                # Odd positions get even values\n","                expected_buf[i] = i - 1\n","\n","        with output_buf.map_to_host() as output_host:\n","            print(\"output:\", output_host)\n","            print(\"expected:\", expected_buf)\n","            for i in range(SIZE):\n","                assert_equal(output_host[i], expected_buf[i])\n","\n","    print(\"✅ Butterfly pair swap test passed!\")\n","\n","\n","def test_butterfly_parallel_max():\n","    with DeviceContext() as ctx:\n","        input_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","        output_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","\n","        with input_buf.map_to_host() as input_host:\n","            for i in range(SIZE):\n","                input_host[i] = i * 2\n","            # Make sure we have a clear maximum\n","            input_host[SIZE - 1] = 1000.0\n","\n","        input_tensor = LayoutTensor[mut=False, dtype, layout](\n","            input_buf.unsafe_ptr()\n","        )\n","        output_tensor = LayoutTensor[mut=False, dtype, layout](\n","            output_buf.unsafe_ptr()\n","        )\n","\n","        ctx.enqueue_function[butterfly_parallel_max[layout, SIZE]](\n","            output_tensor,\n","            input_tensor,\n","            grid_dim=BLOCKS_PER_GRID,\n","            block_dim=THREADS_PER_BLOCK,\n","        )\n","\n","        ctx.synchronize()\n","\n","        expected_buf = ctx.enqueue_create_host_buffer[dtype](SIZE).enqueue_fill(\n","            1000.0\n","        )\n","\n","        # All threads should have the maximum value (1000.0)\n","        with output_buf.map_to_host() as output_host:\n","            print(\"output:\", output_host)\n","            print(\"expected:\", expected_buf)\n","\n","            for i in range(SIZE):\n","                assert_almost_equal(output_host[i], 1000.0, rtol=1e-5)\n","\n","    print(\"✅ Butterfly parallel max test passed!\")\n","\n","\n","def test_butterfly_conditional_max():\n","    with DeviceContext() as ctx:\n","        input_buf = ctx.enqueue_create_buffer[dtype](SIZE_2).enqueue_fill(0)\n","        output_buf = ctx.enqueue_create_buffer[dtype](SIZE_2).enqueue_fill(0)\n","\n","        with input_buf.map_to_host() as input_host:\n","            for i in range(SIZE_2):\n","                if i < 9:\n","                    values = [3, 1, 7, 2, 9, 4, 8, 5, 6]\n","                    input_host[i] = values[i]\n","                else:\n","                    input_host[i] = i % 10\n","\n","        input_tensor = LayoutTensor[mut=False, dtype, layout_2](\n","            input_buf.unsafe_ptr()\n","        )\n","        output_tensor = LayoutTensor[mut=False, dtype, layout_2](\n","            output_buf.unsafe_ptr()\n","        )\n","\n","        ctx.enqueue_function[butterfly_conditional_max[layout_2, SIZE_2]](\n","            output_tensor,\n","            input_tensor,\n","            grid_dim=BLOCKS_PER_GRID_2,\n","            block_dim=THREADS_PER_BLOCK_2,\n","        )\n","\n","        ctx.synchronize()\n","\n","        expected_buf = ctx.enqueue_create_host_buffer[dtype](\n","            SIZE_2\n","        ).enqueue_fill(0)\n","\n","        # Expected: even lanes get max, odd lanes get min\n","        with input_buf.map_to_host() as input_host:\n","            max_val = input_host[0]\n","            min_val = input_host[0]\n","            for i in range(1, SIZE_2):\n","                if input_host[i] > max_val:\n","                    max_val = input_host[i]\n","                if input_host[i] < min_val:\n","                    min_val = input_host[i]\n","\n","            for i in range(SIZE_2):\n","                if i % 2 == 0:\n","                    expected_buf[i] = max_val\n","                else:\n","                    expected_buf[i] = min_val\n","\n","        with output_buf.map_to_host() as output_host:\n","            print(\"output:\", output_host)\n","            print(\"expected:\", expected_buf)\n","\n","            for i in range(SIZE_2):\n","                if i % 2 == 0:\n","                    assert_almost_equal(output_host[i], max_val, rtol=1e-5)\n","                else:\n","                    assert_almost_equal(output_host[i], min_val, rtol=1e-5)\n","\n","    print(\"✅ Butterfly conditional max test passed!\")\n","\n","\n","def test_warp_inclusive_prefix_sum():\n","    with DeviceContext() as ctx:\n","        input_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","        output_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","\n","        with input_buf.map_to_host() as input_host:\n","            for i in range(SIZE):\n","                input_host[i] = i + 1\n","\n","        input_tensor = LayoutTensor[mut=False, dtype, layout](\n","            input_buf.unsafe_ptr()\n","        )\n","        output_tensor = LayoutTensor[mut=False, dtype, layout](\n","            output_buf.unsafe_ptr()\n","        )\n","\n","        ctx.enqueue_function[warp_inclusive_prefix_sum[layout, SIZE]](\n","            output_tensor,\n","            input_tensor,\n","            grid_dim=BLOCKS_PER_GRID,\n","            block_dim=THREADS_PER_BLOCK,\n","        )\n","\n","        expected_buf = ctx.enqueue_create_host_buffer[dtype](SIZE).enqueue_fill(\n","            0\n","        )\n","        ctx.synchronize()\n","\n","        # Create expected inclusive prefix sum: [1, 3, 6, 10, 15, 21, 28, 36, ...]\n","        with input_buf.map_to_host() as input_host:\n","            expected_buf[0] = input_host[0]\n","            for i in range(1, SIZE):\n","                expected_buf[i] = expected_buf[i - 1] + input_host[i]\n","\n","        with output_buf.map_to_host() as output_host:\n","            print(\"output:\", output_host)\n","            print(\"expected:\", expected_buf)\n","            for i in range(SIZE):\n","                assert_almost_equal(output_host[i], expected_buf[i], rtol=1e-5)\n","\n","    print(\"✅ Warp inclusive prefix sum test passed!\")\n","\n","\n","def test_warp_partition():\n","    with DeviceContext() as ctx:\n","        input_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","        output_buf = ctx.enqueue_create_buffer[dtype](SIZE).enqueue_fill(0)\n","\n","        # Create test data: mix of values above and below pivot\n","        pivot_value = Float32(5.0)\n","        with input_buf.map_to_host() as input_host:\n","            # Create: [3, 7, 1, 8, 2, 9, 4, 6, ...]\n","            test_values = [3, 7, 1, 8, 2, 9, 4, 6, 0, 10, 3, 11, 1, 12, 4, 13]\n","            for i in range(SIZE):\n","                input_host[i] = test_values[i % len(test_values)]\n","\n","        input_tensor = LayoutTensor[mut=False, dtype, layout](\n","            input_buf.unsafe_ptr()\n","        )\n","        output_tensor = LayoutTensor[mut=False, dtype, layout](\n","            output_buf.unsafe_ptr()\n","        )\n","\n","        ctx.enqueue_function[warp_partition[layout, SIZE]](\n","            output_tensor,\n","            input_tensor,\n","            pivot_value,\n","            grid_dim=BLOCKS_PER_GRID,\n","            block_dim=THREADS_PER_BLOCK,\n","        )\n","\n","        expected_buf = ctx.enqueue_create_host_buffer[dtype](SIZE).enqueue_fill(\n","            0\n","        )\n","        ctx.synchronize()\n","\n","        # Create expected results: elements < 5 on left, >= 5 on right\n","        with input_buf.map_to_host() as input_host:\n","            left_values = List[Float32]()\n","            right_values = List[Float32]()\n","\n","            for i in range(SIZE):\n","                if input_host[i] < pivot_value:\n","                    left_values.append(input_host[i])\n","                else:\n","                    right_values.append(input_host[i])\n","\n","            # Fill expected buffer\n","            for i in range(len(left_values)):\n","                expected_buf[i] = left_values[i]\n","            for i in range(len(right_values)):\n","                expected_buf[len(left_values) + i] = right_values[i]\n","\n","        with output_buf.map_to_host() as output_host:\n","            print(\"output:\", output_host)\n","            print(\"expected:\", expected_buf)\n","            print(\"pivot:\", pivot_value)\n","\n","            # Verify partitioning property (left < pivot, right >= pivot)\n","            # Find partition boundary\n","            var partition_point = 0\n","            for i in range(SIZE):\n","                if output_host[i] >= pivot_value:\n","                    partition_point = i\n","                    break\n","\n","            # Check left partition\n","            for i in range(partition_point):\n","                if output_host[i] >= pivot_value:\n","                    print(\"ERROR: Left partition contains value >= pivot\")\n","\n","            # Check right partition\n","            for i in range(partition_point, SIZE):\n","                if output_host[i] < pivot_value:\n","                    print(\"ERROR: Right partition contains value < pivot\")\n","\n","    print(\"✅ Warp partition test passed!\")\n","\n","\n","def main():\n","    print(\"WARP_SIZE: \", WARP_SIZE)\n","    if len(argv()) < 2:\n","        print(\n","            \"Usage: p24.mojo\"\n","            \" [--pair-swap|--parallel-max|--conditional-max|--prefix-sum|--partition]\"\n","        )\n","        return\n","\n","    test_type = argv()[1]\n","    if test_type == \"--pair-swap\":\n","        print(\"SIZE: \", SIZE)\n","        test_butterfly_pair_swap()\n","    elif test_type == \"--parallel-max\":\n","        print(\"SIZE: \", SIZE)\n","        test_butterfly_parallel_max()\n","    elif test_type == \"--conditional-max\":\n","        print(\"SIZE: \", SIZE_2)\n","        test_butterfly_conditional_max()\n","    elif test_type == \"--prefix-sum\":\n","        print(\"SIZE: \", SIZE)\n","        test_warp_inclusive_prefix_sum()\n","    elif test_type == \"--partition\":\n","        print(\"SIZE: \", SIZE)\n","        test_warp_partition()\n","    else:\n","        print(\n","            \"Usage: p24.mojo\"\n","            \" [--pair-swap|--parallel-max|--conditional-max|--prefix-sum|--partition]\"\n","        )\n","\"\"\""],"metadata":{"id":"PmyLQO9PsA-O","executionInfo":{"status":"ok","timestamp":1756808252574,"user_tz":-330,"elapsed":56,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["save_code_to_file(mojo_code, \"/content/mojo-gpu-puzzles/problems/p26/p26.mojo\")"],"metadata":{"id":"CgJCXMQlsBu2","executionInfo":{"status":"ok","timestamp":1756808252694,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!cd /content/mojo-gpu-puzzles && uv run poe p26 --partition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bdRF-rZAsBwn","executionInfo":{"status":"ok","timestamp":1756808264431,"user_tz":-330,"elapsed":11536,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"015b1874-fcc0-41af-acb5-9b64b8f07216"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[37mPoe =>\u001b[0m \u001b[94mmojo problems/p26/p26.mojo --prefix-sum\u001b[0m\n","\u001b[1m/content/mojo-gpu-puzzles/problems/p26/p26.mojo:129:28: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1massignment to 'current_val' was never used; assign to '_' instead?\n","\u001b[0m        current_val = input[global_i]\n","\u001b[0;1;32m                           ^\n","\u001b[0mWARP_SIZE:  32\n","SIZE:  32\n","output: HostBuffer([1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0, 36.0, 45.0, 55.0, 66.0, 78.0, 91.0, 105.0, 120.0, 136.0, 153.0, 171.0, 190.0, 210.0, 231.0, 253.0, 276.0, 300.0, 325.0, 351.0, 378.0, 406.0, 435.0, 465.0, 496.0, 528.0])\n","expected: HostBuffer([1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0, 36.0, 45.0, 55.0, 66.0, 78.0, 91.0, 105.0, 120.0, 136.0, 153.0, 171.0, 190.0, 210.0, 231.0, 253.0, 276.0, 300.0, 325.0, 351.0, 378.0, 406.0, 435.0, 465.0, 496.0, 528.0])\n","✅ Warp inclusive prefix sum test passed!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zImeM50LsByy","executionInfo":{"status":"ok","timestamp":1756807678604,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QSP4lDSVsB0a","executionInfo":{"status":"ok","timestamp":1756807678614,"user_tz":-330,"elapsed":8,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":8,"outputs":[]}]}