{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN1iYpzF2B+KtRV5k148mUB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AoGcUvzCOjK","executionInfo":{"status":"ok","timestamp":1756575144340,"user_tz":-330,"elapsed":27187,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"b4d92ca5-c944-43db-d0aa-b719f8c72972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://dl.modular.com/public/nightly/python/simple/\n","Collecting max==25.4.0\n","  Downloading https://dl.modular.com/public/nightly/python/max-25.4.0-py3-none-manylinux_2_34_x86_64.whl (285.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.0/285.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (8.2.1)\n","Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (2.0.2)\n","Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from max==25.4.0) (4.67.1)\n","Installing collected packages: max\n","Successfully installed max-25.4.0\n"]}],"source":["!pip install max==25.4.0 --index-url https://dl.modular.com/public/nightly/python/simple/"]},{"cell_type":"code","source":["!git clone https://github.com/modular/mojo-gpu-puzzles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQvoJu7nCRno","executionInfo":{"status":"ok","timestamp":1756575157613,"user_tz":-330,"elapsed":13268,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"dfeff8cb-2183-430e-fc91-5ec8d9070586"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mojo-gpu-puzzles'...\n","remote: Enumerating objects: 6332, done.\u001b[K\n","remote: Counting objects: 100% (481/481), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 6332 (delta 449), reused 416 (delta 416), pack-reused 5851 (from 3)\u001b[K\n","Receiving objects: 100% (6332/6332), 148.64 MiB | 14.78 MiB/s, done.\n","Resolving deltas: 100% (3923/3923), done.\n"]}]},{"cell_type":"code","source":["!curl -fsSL https://astral.sh/uv/install.sh | sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4u6He1ejCTXV","executionInfo":{"status":"ok","timestamp":1756575159934,"user_tz":-330,"elapsed":2311,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"490f51de-cdeb-4ded-b6b1-e989e69b91a1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading uv 0.8.14 x86_64-unknown-linux-gnu\n","no checksums to verify\n","installing to /usr/local/bin\n","  uv\n","  uvx\n","everything's installed!\n"]}]},{"cell_type":"code","source":["import max.support.notebook"],"metadata":{"id":"7KfTRBW6CUwk","executionInfo":{"status":"ok","timestamp":1756575159949,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def save_code_to_file(text: str, filename: str):\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(text)"],"metadata":{"id":"loGxUnbFCWTx","executionInfo":{"status":"ok","timestamp":1756575160002,"user_tz":-330,"elapsed":1,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mojo_code = \"\"\"\n","from math import ceildiv\n","from gpu import thread_idx, block_idx, block_dim, grid_dim, barrier\n","from gpu.host import DeviceContext\n","from layout import Layout, LayoutTensor\n","from layout.tensor_builder import LayoutTensorBuild as tb\n","from sys.info import sizeof\n","from sys.arg import argv\n","from testing import assert_equal\n","\n","# ANCHOR: embedding_kernel_coalesced\n","alias THREADS_PER_BLOCK = 256\n","\n","\n","fn embedding_kernel_coalesced[\n","    indices_layout: Layout,\n","    weights_layout: Layout,\n","    out_layout: Layout,\n","    batch_size: Int,\n","    seq_len: Int,\n","    vocab_size: Int,\n","    embed_dim: Int,\n","    dtype: DType = DType.float32,\n","](\n","    output: LayoutTensor[mut=True, dtype, out_layout],\n","    indices: LayoutTensor[mut=True, DType.int32, indices_layout],\n","    weights: LayoutTensor[mut=True, dtype, weights_layout],\n","):\n","\n","    # Simple 1D indexing - each thread = one output element\n","    global_idx = block_idx.x * block_dim.x + thread_idx.x\n","    total_elements = batch_size * seq_len * embed_dim\n","\n","    if global_idx >= total_elements:\n","        return\n","\n","    # Convert to (batch, seq, embed) coordinates\n","    # FILL IN roughly 4 lines\n","    batch_idx = global_idx // (seq_len * embed_dim)\n","    remaining = global_idx % (seq_len * embed_dim)\n","    seq_idx = remaining // embed_dim\n","    embed_idx = remaining % embed_dim\n","\n","    # Get token index\n","    # FILL IN 1 line\n","    token_idx_val = Int(indices[batch_idx, seq_idx])\n","\n","    # Simple, correct assignment\n","    # FILL IN 4 lines\n","    if token_idx_val >= 0 and token_idx_val < vocab_size:\n","      output[batch_idx, seq_idx, embed_idx] = weights[\n","        token_idx_val, embed_idx\n","      ]\n","    else:\n","      output[batch_idx, seq_idx, embed_idx] = 0\n","\n","# ANCHOR_END: embedding_kernel_coalesced\n","\n","\n","# ANCHOR: embedding_kernel_2d\n","fn embedding_kernel_2d[\n","    indices_layout: Layout,\n","    weights_layout: Layout,\n","    out_layout: Layout,\n","    batch_size: Int,\n","    seq_len: Int,\n","    vocab_size: Int,\n","    embed_dim: Int,\n","    dtype: DType = DType.float32,\n","](\n","    output: LayoutTensor[mut=True, dtype, out_layout],\n","    indices: LayoutTensor[mut=True, DType.int32, indices_layout],\n","    weights: LayoutTensor[mut=True, dtype, weights_layout],\n","):\n","\n","    # 2D grid indexing\n","    batch_seq_idx = block_idx.x * block_dim.x + thread_idx.x\n","    embed_idx = block_idx.y * block_dim.y + thread_idx.y\n","    total_positions = batch_size * seq_len\n","\n","    if batch_seq_idx >= total_positions or embed_idx >= embed_dim:\n","        return\n","\n","    # Convert to (batch, seq) coordinates\n","    # FILL IN 2 lines\n","    batch_idx = batch_seq_idx // seq_len\n","    seq_idx = batch_seq_idx % seq_len\n","\n","    # Get token index\n","    # FILL IN 1 line\n","    token_idx_val = Int(indices[batch_idx, seq_idx])\n","\n","    # Assignment with 2D grid pattern\n","    # FILL IN 4 lines\n","    if token_idx_val >= 0 and token_idx_val < vocab_size:\n","      output[batch_idx, seq_idx, embed_idx] = weights[token_idx_val, embed_idx]\n","    else:\n","      output[batch_idx, seq_idx, embed_idx] = 0\n","\n","# ANCHOR_END: embedding_kernel_2d\n","\n","import compiler\n","from runtime.asyncrt import DeviceContextPtr\n","from tensor import InputTensor, OutputTensor\n","from memory import UnsafePointer\n","from gpu.host import DeviceBuffer\n","\n","\n","@compiler.register(\"embedding\")\n","struct EmbeddingCustomOp:\n","    @staticmethod\n","    fn execute[\n","        target: StaticString,\n","        batch_size: Int,\n","        seq_len: Int,\n","        vocab_size: Int,\n","        embed_dim: Int,\n","    ](\n","        output: OutputTensor[\n","            dtype = DType.float32, rank=3\n","        ],  # [batch_size, seq_len, embed_dim]\n","        indices: InputTensor[\n","            dtype = DType.int32, rank=2\n","        ],  # [batch_size, seq_len]\n","        weights: InputTensor[\n","            dtype = output.dtype, rank=2\n","        ],  # [vocab_size, embed_dim]\n","        ctx: DeviceContextPtr,\n","    ) raises:\n","        output_tensor = output.to_layout_tensor()\n","        indices_tensor = indices.to_layout_tensor()\n","        weights_tensor = weights.to_layout_tensor()\n","\n","        alias indices_layout = indices_tensor.layout\n","        alias weights_layout = weights_tensor.layout\n","        alias out_layout = output_tensor.layout\n","\n","        @parameter\n","        if target == \"gpu\":\n","            gpu_ctx = ctx.get_device_context()\n","\n","            # Zero out output tensor\n","            gpu_ctx.enqueue_memset(\n","                DeviceBuffer[output.dtype](\n","                    gpu_ctx,\n","                    rebind[UnsafePointer[Scalar[output.dtype]]](\n","                        output_tensor.ptr\n","                    ),\n","                    batch_size * seq_len * embed_dim,\n","                    owning=False,\n","                ),\n","                0,\n","            )\n","\n","            # Calculate 1D grid dimensions (matching kernel's flat indexing)\n","            total_elements = batch_size * seq_len * embed_dim\n","            blocks = max(1, ceildiv(total_elements, THREADS_PER_BLOCK))\n","\n","            # Compile and launch optimized kernel\n","            compiled_kernel = gpu_ctx.compile_function[\n","                embedding_kernel_coalesced[\n","                    indices_layout,\n","                    weights_layout,\n","                    out_layout,\n","                    batch_size,\n","                    seq_len,\n","                    vocab_size,\n","                    embed_dim,\n","                    output.dtype,\n","                ]\n","            ]()\n","\n","            gpu_ctx.enqueue_function(\n","                compiled_kernel,\n","                output_tensor,\n","                indices_tensor,\n","                weights_tensor,\n","                grid_dim=(blocks,),\n","                block_dim=(THREADS_PER_BLOCK,),\n","            )\n","\n","        elif target == \"cpu\":\n","            for batch in range(batch_size):\n","                for seq in range(seq_len):\n","                    token_idx_val = Int(indices_tensor[batch, seq])\n","                    if token_idx_val >= 0 and token_idx_val < vocab_size:\n","                        for emb in range(embed_dim):\n","                            output_tensor[batch, seq, emb] = weights_tensor[\n","                                token_idx_val, emb\n","                            ]\n","        else:\n","            raise Error(\"Unsupported target: \" + target)\n","\n","\n","@compiler.register(\"embedding_2d\")\n","struct Embedding2DCustomOp:\n","    @staticmethod\n","    fn execute[\n","        target: StaticString,\n","        batch_size: Int,\n","        seq_len: Int,\n","        vocab_size: Int,\n","        embed_dim: Int,\n","    ](\n","        output: OutputTensor[\n","            dtype = DType.float32, rank=3\n","        ],  # [batch_size, seq_len, embed_dim]\n","        indices: InputTensor[\n","            dtype = DType.int32, rank=2\n","        ],  # [batch_size, seq_len]\n","        weights: InputTensor[\n","            dtype = output.dtype, rank=2\n","        ],  # [vocab_size, embed_dim]\n","        ctx: DeviceContextPtr,\n","    ) raises:\n","        output_tensor = output.to_layout_tensor()\n","        indices_tensor = indices.to_layout_tensor()\n","        weights_tensor = weights.to_layout_tensor()\n","\n","        alias indices_layout = indices_tensor.layout\n","        alias weights_layout = weights_tensor.layout\n","        alias out_layout = output_tensor.layout\n","\n","        @parameter\n","        if target == \"gpu\":\n","            gpu_ctx = ctx.get_device_context()\n","\n","            # Zero out output tensor\n","            gpu_ctx.enqueue_memset(\n","                DeviceBuffer[output.dtype](\n","                    gpu_ctx,\n","                    rebind[UnsafePointer[Scalar[output.dtype]]](\n","                        output_tensor.ptr\n","                    ),\n","                    batch_size * seq_len * embed_dim,\n","                    owning=False,\n","                ),\n","                0,\n","            )\n","\n","            # Calculate 2D grid dimensions for non-coalesced access\n","            total_positions = batch_size * seq_len\n","            alias BLOCK_X = 16  # batch*seq dimension\n","            alias BLOCK_Y = 16  # embed dimension\n","            blocks_x = max(1, ceildiv(total_positions, BLOCK_X))\n","            blocks_y = max(1, ceildiv(embed_dim, BLOCK_Y))\n","\n","            # Compile and launch 2D kernel\n","            compiled_kernel = gpu_ctx.compile_function[\n","                embedding_kernel_2d[\n","                    indices_layout,\n","                    weights_layout,\n","                    out_layout,\n","                    batch_size,\n","                    seq_len,\n","                    vocab_size,\n","                    embed_dim,\n","                    output.dtype,\n","                ]\n","            ]()\n","\n","            gpu_ctx.enqueue_function(\n","                compiled_kernel,\n","                output_tensor,\n","                indices_tensor,\n","                weights_tensor,\n","                grid_dim=(blocks_x, blocks_y),\n","                block_dim=(BLOCK_X, BLOCK_Y),\n","            )\n","\n","        elif target == \"cpu\":\n","            # Same CPU fallback as 1D version\n","            for batch in range(batch_size):\n","                for seq in range(seq_len):\n","                    token_idx_val = Int(indices_tensor[batch, seq])\n","                    if token_idx_val >= 0 and token_idx_val < vocab_size:\n","                        for emb in range(embed_dim):\n","                            output_tensor[batch, seq, emb] = weights_tensor[\n","                                token_idx_val, emb\n","                            ]\n","        else:\n","            raise Error(\"Unsupported target: \" + target)\n","\n","\"\"\""],"metadata":{"id":"Eu9H7kP-CdIF","executionInfo":{"status":"ok","timestamp":1756575975875,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["save_code_to_file(mojo_code, \"/content/mojo-gpu-puzzles/problems/p21/op/embedding.mojo\")"],"metadata":{"id":"ui9-VLoYCdbe","executionInfo":{"status":"ok","timestamp":1756575976105,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!cd /content/mojo-gpu-puzzles && uv run poe p21"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Q0fqQDpCddT","executionInfo":{"status":"ok","timestamp":1756576009619,"user_tz":-330,"elapsed":33279,"user":{"displayName":"Mojonized","userId":"01435840102907113887"}},"outputId":"29532f77-ae40-45cf-ec79-5864eadbd6d2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[37mPoe =>\u001b[0m \u001b[94mpython problems/p21/p21.py\u001b[0m\n","Puzzle 19: Mojo Embedding Kernel Comparison\n","======================================================================\n","\n","Configuration: B=8, L=512, V=10000, E=512\n","------------------------------------------------------------\n","Testing Correctness...\n","   1D Coalesced - Max difference: 0.00e+00\n","   2D Non-coalesced - Max difference: 0.00e+00\n","   ✅ Both implementations CORRECT\n","\n","Benchmarking Mojo Kernels...\n","\n","Performance Results:\n","   1D Coalesced:     0.401 ms\n","   2D Non-coalesced: 0.426 ms\n","   1D is 1.06x faster than 2D\n","\n","Key Learning Points:\n","• Compare different GPU kernel implementations\n","• 1D vs 2D grid patterns have different memory access\n","• Coalesced memory access should be faster\n","• Grid configuration affects GPU utilization\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IqbOFz0mCdfD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6jbtPA78Cdg3"},"execution_count":null,"outputs":[]}]}